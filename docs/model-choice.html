<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 10 Model Choice | Gov 50: Data" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 10 Model Choice | Gov 50: Data">

<title>Chapter 10 Model Choice | Gov 50: Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Gov 50: Data<p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"></a>
<a href="preamble.html">Preamble</a>
<a href="shopping-week.html">Shopping Week</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Wrangling</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a href="one-parameter.html"><span class="toc-section-number">6</span> One Parameter</a>
<a href="two-parameters.html"><span class="toc-section-number">7</span> Two Parameters</a>
<a href="three-parameters.html"><span class="toc-section-number">8</span> Three Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a id="active-page" href="model-choice.html"><span class="toc-section-number">10</span> Model Choice</a><ul class="toc-sections">
<li class="toc"><a href="#ames"> The Ames housing data</a></li>
<li class="toc"><a href="#splitting"> Spending our data</a></li>
<li class="toc"><a href="#recipes"> Feature engineering with recipes</a></li>
<li class="toc"><a href="#models"> Fitting models with parsnip</a></li>
<li class="toc"><a href="#performance"> Judging model effectiveness</a></li>
</ul>
<a href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="tools.html">Tools</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="references.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="model-choice" class="section level1">
<h1>
<span class="header-section-number">Chapter 10</span> Model Choice</h1>
<p>Still a draft. Come back in a few weeks.</p>
<div id="ames" class="section level2">
<h2>
<span class="header-section-number">10.1</span> The Ames housing data</h2>
<p>The Ames housing data set is an excellent resource for learning about models that we will use throughout this book. It contains data on 2,930 properties in Ames, Iowa, including columns related to</p>
<ul>
<li>house characteristics (bedrooms, garage, fireplace, pool, porch, etc.),</li>
<li>location (neighborhood),</li>
<li>lot information (zoning, shape, size, etc.),</li>
<li>ratings of condition and quality, and</li>
<li>sale price.</li>
</ul>
<p>We use a transformed version available in the <strong>modeldata</strong> package. This version has several changes and improvements to the data. For example, the longitude and latitude values have been determined for each property. Also, some columns were modified to be more analysis ready. For example:</p>
<ul>
<li><p>In the raw data, if a house did not have a particular feature, it was implicitly encoded as missing. For example, there were 2,732 properties that did not have an alleyway. Instead of leaving these as missing, they were relabeled in the transformed version to indicate that no alley was available.</p></li>
<li><p>The categorical predictors were converted to R’s factor data type. While both the tidyverse and base R have moved away from importing data as factors by default, this data type is a better approach for storing qualitative data for <em>modeling</em> than simple strings.</p></li>
<li><p>We removed a set of quality descriptors for each house since they are more like outcomes than predictors.</p></li>
</ul>
<p>To load the data:</p>
<div class="sourceCode" id="cb972"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb972-1"><a href="model-choice.html#cb972-1"></a><span class="kw">library</span>(modeldata) <span class="co"># This is also loaded by the tidymodels package</span></span>
<span id="cb972-2"><a href="model-choice.html#cb972-2"></a><span class="kw">data</span>(ames)</span>
<span id="cb972-3"><a href="model-choice.html#cb972-3"></a></span>
<span id="cb972-4"><a href="model-choice.html#cb972-4"></a><span class="co"># or, in one line:</span></span>
<span id="cb972-5"><a href="model-choice.html#cb972-5"></a><span class="kw">data</span>(ames, <span class="dt">package =</span> <span class="st">"modeldata"</span>)</span>
<span id="cb972-6"><a href="model-choice.html#cb972-6"></a></span>
<span id="cb972-7"><a href="model-choice.html#cb972-7"></a><span class="kw">dim</span>(ames)</span></code></pre></div>
<pre><code>## [1] 2930   74</code></pre>
<div id="exploring-important-features" class="section level3">
<h3>
<span class="header-section-number">10.1.1</span> Exploring important features</h3>
<p>It makes sense to start with the outcome we want to predict: the last sale price of the house (in USD):</p>
<div class="sourceCode" id="cb974"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb974-1"><a href="model-choice.html#cb974-1"></a><span class="kw">ggplot</span>(ames, <span class="kw">aes</span>(<span class="dt">x =</span> Sale_Price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb974-2"><a href="model-choice.html#cb974-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">50</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-796-1.png" width="672"></p>
<p>The data are right-skewed; there are more inexpensive houses than expensive ones. The median sale price was $160,000 and the most expensive house was $755,000. When modeling this outcome, a strong argument can be made that the price should be log-transformed. The advantages of doing this are that no houses would be predicted with negative sale prices and that errors in predicting expensive houses will not have an undue influence on the model. Also, from a statistical perspective, a logarithmic transform may also <em>stabilize the variance</em> in a way that makes inference more legitimate. Let’s visualize the transformed data:</p>
<div class="sourceCode" id="cb975"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb975-1"><a href="model-choice.html#cb975-1"></a><span class="kw">ggplot</span>(ames, <span class="kw">aes</span>(<span class="dt">x =</span> Sale_Price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb975-2"><a href="model-choice.html#cb975-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">50</span>) <span class="op">+</span></span>
<span id="cb975-3"><a href="model-choice.html#cb975-3"></a><span class="st">  </span><span class="kw">scale_x_log10</span>()</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-797-1.png" width="672"></p>
<p>While not perfect, this will probably result in better models than using the untransformed data.</p>
<p>The units of the model coefficients might be more difficult to interpret, as will measures of performance. For example, the root mean squared error (RMSE) is a common performance metric that is used in regression models. It uses the difference between the observed and predicted values in its calculations. If the sale price is on the log scale, these differences (i.e. the residuals) are also in log units. For this reason, it can be difficult to understand the quality of a model whose RMSE is 0.15 log units.</p>
<p>Despite these drawbacks, the models used in this book utilize the log transformation for this outcome. <em>From this point on</em>, the outcome column is pre-logged in the <code>ames</code> data frame:</p>
<div class="sourceCode" id="cb976"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb976-1"><a href="model-choice.html#cb976-1"></a>ames &lt;-<span class="st"> </span>ames <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb976-2"><a href="model-choice.html#cb976-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sale_Price =</span> <span class="kw">log10</span>(Sale_Price))</span></code></pre></div>
<p>Another important aspect of these data for our modeling are their geographic locations. This spatial information is contained in the data in two ways: a qualitative <code>Neighborhood</code> label as well as quantitative longitude and latitude data. To visualize the spatial information, let’s use both together to plot the data on a map and color by neighborhood:</p>
<p><img src="10-model-choice/images/ames.png" width="1230"></p>
<p>We can see a few noticeable patterns. First, there is a void of data points in the center of Ames. This corresponds to Iowa State University. Second, while there are a number of neighborhoods that are geographically isolated, there are others that are adjacent to each other. For example, Timberland is located apart from almost all other neighborhoods:</p>
<p><img src="10-model-choice/images/timberland.png" width="488"></p>
<p>The Meadow Village neighborhood in Southwest Ames is like an island of properties ensconced inside the sea of properties that make up the Mitchell neighborhood:</p>
<p><img src="10-model-choice/images/mitchell.png" width="710"></p>
<p>A detailed inspection of the map also shows that the neighborhood labels are not completely reliable. For example, there are some properties labeled as being in Northridge that are surrounded by houses in the adjacent Somerset neighborhood:</p>
<p><img src="10-model-choice/images/northridge.png" width="580"></p>
<p>Also, there are ten isolated houses labeled as being in Crawford but are not close to the majority of the other houses in that neighborhood:</p>
<p><img src="10-model-choice/images/crawford.png" width="460"></p>
<p>Also notable is the “Iowa Department of Transportation (DOT) and Rail Road” neighborhood adjacent to the main road on the east side of Ames. There are several clusters of houses within this neighborhood as well as some longitudinal outliers; the two houses furthest east are isolated from the other locations.</p>
<p><img src="10-model-choice/images/dot_rr.png" width="792"></p>
<p>It is critical to conduct <em>exploratory data analysis</em> prior to beginning any modeling. These housing data have characteristics that present interesting challenges about how the data should be processed and modeled. We describe many of these in later chapters. Some basic questions that could be examined include:</p>
<ul>
<li><p>Are there any odd or noticeable things about the distributions of the individual predictors? Is there much skewness or any pathological distributions?</p></li>
<li><p>Are there high correlations between predictors? For example, there are multiple predictors related to the size of the house. Are some redundant?</p></li>
<li><p>Are there associations between predictors and the outcomes?</p></li>
</ul>
<p>Many of these questions will be revisited as these data are used in upcoming examples.The important code that we will carry forward is:</p>
<div class="sourceCode" id="cb977"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb977-1"><a href="model-choice.html#cb977-1"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb977-2"><a href="model-choice.html#cb977-2"></a><span class="kw">data</span>(ames)</span>
<span id="cb977-3"><a href="model-choice.html#cb977-3"></a>ames &lt;-<span class="st"> </span>ames <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb977-4"><a href="model-choice.html#cb977-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sale_Price =</span> <span class="kw">log10</span>(Sale_Price))</span></code></pre></div>
</div>
</div>
<div id="splitting" class="section level2">
<h2>
<span class="header-section-number">10.2</span> Spending our data</h2>
<p>There are several steps to create a useful model, including parameter estimation, model selection and tuning, and performance assessment. At the start of a new project, there is usually an initial finite pool of data available for all these tasks. How should the data be applied to these steps? The idea of <em>data spending</em> is an important first consideration when modeling, especially as it relates to empirical validation.</p>
<p>When there are copious amounts of data available, a smart strategy is to allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only. There may be questions about many modeling project steps that must be answered with limited prior knowledge. For example, one possible strategy (when both data and predictors are abundant) is to spend a specific subset of data to determine which predictors are informative, before considering parameter estimation at all.</p>
<p>If the initial pool of data available is not huge, there will be some overlap of how and when our data is “spent” or allocated, and a solid methodology for data spending is important. Here, we demonstrate the basics of <em>splitting</em> our initial pool of samples for different purposes.</p>
<div id="splitting-methods" class="section level3">
<h3>
<span class="header-section-number">10.2.1</span> Common methods for splitting data</h3>
<p>The primary approach for empirical model validation is to split the existing pool of data into two distinct sets. Some observations are used to develop and optimize the model. This <em>training set</em> is usually the majority of the data. These data are a sandbox for model building where different models can be fit, feature engineering strategies are investigated, and so on. We as modeling practitioners spend the vast majority of the modeling process using the training set as the substrate to develop the model.</p>
<p>The other portion of the observations are placed into the <em>test set</em>. This is held in reserve until one or two models are chosen as the methods that are mostly likely to succeed. The test set is then used as the final arbiter to determine the efficacy of the model. It is critical to only look at the test set once; otherwise, it becomes part of the modeling process.</p>
<p>Suppose we allocate 80% of the data to the training set and the remaining 20% for testing. The most common method is to use simple random sampling. The <strong>rsample</strong> package has tools for making data splits such as this; the function <code>intial_split()</code> was created for this purpose. It takes the data frame as an argument as well as the proportion to be placed into training. Using the previous data frame produced by the code snippet from the summary in Section <a href="#ames-summary"><strong>??</strong></a>:</p>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb978-1"><a href="model-choice.html#cb978-1"></a><span class="co"># Set the random number stream using `set.seed()` so that the results can be </span></span>
<span id="cb978-2"><a href="model-choice.html#cb978-2"></a><span class="co"># reproduced later. </span></span>
<span id="cb978-3"><a href="model-choice.html#cb978-3"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb978-4"><a href="model-choice.html#cb978-4"></a></span>
<span id="cb978-5"><a href="model-choice.html#cb978-5"></a><span class="co"># Save the split information for an 80/20 split of the data</span></span>
<span id="cb978-6"><a href="model-choice.html#cb978-6"></a>ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ames, <span class="dt">prob =</span> <span class="fl">0.80</span>)</span>
<span id="cb978-7"><a href="model-choice.html#cb978-7"></a>ames_split</span></code></pre></div>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;2198/732/2930&gt;</code></pre>
<p>The printed information denotes the amount of data in the training set (<span class="math inline">\(n = 2,198\)</span>), the amount in the test set (<span class="math inline">\(n = 732\)</span>), and the size of the original pool of samples (<span class="math inline">\(n = 2,930\)</span>).</p>
<p>The object <code>ames_split</code> is an <code>rsplit</code> object and only contains the partitioning information; to get the resulting data sets, we apply two more functions:</p>
<div class="sourceCode" id="cb980"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb980-1"><a href="model-choice.html#cb980-1"></a>ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)</span>
<span id="cb980-2"><a href="model-choice.html#cb980-2"></a>ames_test  &lt;-<span class="st">  </span><span class="kw">testing</span>(ames_split)</span>
<span id="cb980-3"><a href="model-choice.html#cb980-3"></a></span>
<span id="cb980-4"><a href="model-choice.html#cb980-4"></a><span class="kw">dim</span>(ames_train)</span></code></pre></div>
<pre><code>## [1] 2198   74</code></pre>
<p>These objects are data frames with the same <em>columns</em> as the original data but only the appropriate <em>rows</em> for each set.</p>
<p>Simple random sampling is appropriate in many cases but there are exceptions. When there is a dramatic <em>class imbalance</em> in classification problems, one class occurs much less frequently than another. Using a simple random sample may haphazardly allocate these infrequent samples disproportionately into the training or test set. To avoid this, <em>stratified sampling</em> can be used. The training/test split is conducted separately within each class and then these subsamples are combined into the overall training and test set. For regression problems, the outcome data can be artificially binned into <em>quartiles</em> and then stratified sampling conducted four separate times. This is an effective method for keeping the distributions of the outcome similar between the training and test set.</p>
<div class="figure">
<span id="fig:unnamed-chunk-808"></span>
<p class="caption marginnote shownote">
FIGURE 10.1: The distribution of the sale price (in log units) for the Ames housing data. The vertical lines indicate the quartiles of the data.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-808-1.png" alt="The distribution of the sale price (in log units) for the Ames housing data. The vertical lines indicate the quartiles of the data." width="672">
</div>
<p>Consider the distribution of the sale price outcome for the Ames housing data. As previously discussed, the sale price distribution is right-skewed, with proportionally more expensive houses than inexpensive houses on either side of the center of the distribution. The worry here is that the more expensive houses would not be represented in the training set well with simple splitting; this would increase the risk that our model would be ineffective at predicting the price for such properties. The dotted vertical lines indicate the four quartiles for these data. A stratified random sample would conduct the 80/20 split within each of these data subsets and then pool the results together. In <strong>rsample</strong>, this is achieved using the <code>strata</code> argument:</p>
<!-- DK: Cut this strata stuff? -->
<div class="sourceCode" id="cb982"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb982-1"><a href="model-choice.html#cb982-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb982-2"><a href="model-choice.html#cb982-2"></a>ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ames, <span class="dt">prob =</span> <span class="fl">0.80</span>, <span class="dt">strata =</span> Sale_Price)</span>
<span id="cb982-3"><a href="model-choice.html#cb982-3"></a>ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)</span>
<span id="cb982-4"><a href="model-choice.html#cb982-4"></a>ames_test  &lt;-<span class="st">  </span><span class="kw">testing</span>(ames_split)</span>
<span id="cb982-5"><a href="model-choice.html#cb982-5"></a></span>
<span id="cb982-6"><a href="model-choice.html#cb982-6"></a><span class="kw">dim</span>(ames_train)</span></code></pre></div>
<pre><code>## [1] 2199   74</code></pre>
<p>Only a single column can be used for stratification.</p>
<p>Are there situations when random sampling is not the best choice? One case is when the data have a significant <em>time</em> component, such as time series data. Here, it is more common to use the most recent data as the test set. The <strong>rsample</strong> package contains a function called <code>initial_time_split()</code> that is very similar to <code>initial_split()</code>. Instead of using random sampling, the <code>prop</code> argument denotes what proportion of the first part of the data should be used as the training set; the function assumes that the data have been pre-sorted in an appropriate order.</p>
</div>
<div id="what-proportion-should-be-used" class="section level3">
<h3>
<span class="header-section-number">10.2.2</span> What proportion should be used?</h3>
<p>The amount of data that should be allocated when splitting the data is highly dependent on the context of the problem at hand. Too much data in the training set lowers the quality of the performance estimates. Conversely, too much data in the test set handicaps the model’s ability to find appropriate parameter estimates. There are parts of the statistics community that eschew test sets in general because they believe all of the data should be used for parameter estimation. While there is merit to this argument, it is good modeling practice to have an unbiased set of observations as the final arbiter of model quality. A test set should be avoided only when the data are pathologically small.</p>
</div>
<div id="what-about-a-validation-set" class="section level3">
<h3>
<span class="header-section-number">10.2.3</span> What about a validation set?</h3>
<p>Previously, when describing the goals of data splitting, we singled out the test set as the data that should be used to conduct a proper evaluation of model performance on the final model(s). This begs the question of, “How can we tell what is best if we don’t measure performance until the test set?”</p>
<p>It is common to hear about <em>validation sets</em> as an answer to this question, especially in the neural network and deep learning literature. The validation set was originally defined in the early days of neural networks when researchers realized that measuring performance by re-predicting the training set samples led to results that were overly optimistic (significantly, unrealistically so). This led to models that overfit, meaning that they performed very well on the training set but poorly on the test set. To combat this issue, a small validation set of data were held back and used to measure performance as the network was trained. Once the validation set error rate began to rise, the training would be halted. In other words, the validation set was a means to get a rough sense of how well the model performed prior to the test set. It is largely semantics as to whether validation sets are a subset of the training set or a third allocation in the initial split of the data.</p>
</div>
<div id="other-considerations" class="section level3">
<h3>
<span class="header-section-number">10.2.4</span> Other considerations</h3>
<p>Throughout this book, notice which data are exposed to the model at any given time. Remember that it is critical to quarantine the test set from any model building activities. The problem of <em>information leakage</em> occurs when data outside of the training set are used in the modeling process.</p>
<p>For example, in a machine learning competition, the test set data might be provided without the true outcome values so that the model can be scored and ranked. One potential method for improving the score might be to fit the model using the training set points that are most similar to the test set values. While the test set isn’t directly used to fit the model, it still has a heavy influence. In general, this technique is highly problematic since it reduces the <em>generalization error</em> of the model to optimize performance on a specific data set. There are more subtle ways that the test set data can be utilized during training. Keeping the training data in a separate data frame from the test set is a one small check to make sure that information leakage does not occur by accident.</p>
<p>We will discuss techniques to subsample the training set to mitigate specific issues (e.g., class imbalances). This is a valid and common technique that deliberately results in the training set data diverging from the population from which the data were drawn. It is critical that the test set continue to mirror what the model would encounter <em>in the wild</em>. In other words, the test set should always resemble new data that will be given to the model.</p>
<p>Data splitting is the fundamental tool for empirical validation for models. Even in the era of unrestrained data collection, a typical modeling project has a limited amount of appropriate data and wise “spending” of a project’s data is necessary. In this chapter, we discussed several strategies for partitioning the data into distinct groups for modeling and evaluation.</p>
<p>At this checkpoint, the important code snippets are:</p>
<div class="sourceCode" id="cb984"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb984-1"><a href="model-choice.html#cb984-1"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb984-2"><a href="model-choice.html#cb984-2"></a><span class="kw">data</span>(ames)</span>
<span id="cb984-3"><a href="model-choice.html#cb984-3"></a>ames &lt;-<span class="st"> </span>ames <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Sale_Price =</span> <span class="kw">log10</span>(Sale_Price))</span>
<span id="cb984-4"><a href="model-choice.html#cb984-4"></a></span>
<span id="cb984-5"><a href="model-choice.html#cb984-5"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb984-6"><a href="model-choice.html#cb984-6"></a>ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ames, <span class="dt">prob =</span> <span class="fl">0.80</span>, <span class="dt">strata =</span> Sale_Price)</span>
<span id="cb984-7"><a href="model-choice.html#cb984-7"></a>ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)</span>
<span id="cb984-8"><a href="model-choice.html#cb984-8"></a>ames_test  &lt;-<span class="st">  </span><span class="kw">testing</span>(ames_split)</span></code></pre></div>
</div>
</div>
<div id="recipes" class="section level2">
<h2>
<span class="header-section-number">10.3</span> Feature engineering with recipes</h2>
<p>Feature engineering encompasses activities that reformat predictor values to make them easier for a model to use effectively. This includes transformations and encodings of the data to best represent their important characteristics. Imagine that you have two predictors in a data set that can be more effectively represented in your model of interest as a ratio; creating a new predictor from the ratio of the original two is a simple example of feature engineering.</p>
<p>Take the location of a house in Ames as a more involved example. There are a variety of ways that this spatial information can be exposed to a model, including neighborhood (a qualitative measure), longitude/latitude, distance to the nearest school or Iowa State University, and so on. When choosing how to encode these data in modeling, we might choose an option we believe most associated with the outcome. The original format of the data (e.g., numeric like distance versus categorical like neighborhood) is also a driving factor in feature engineering choices.</p>
<p>There are many other examples of preprocessing to build better features for modeling:</p>
<ul>
<li><p>Correlation between predictors can be reduced via feature extraction or the removal of some predictors.</p></li>
<li><p>When some predictors have missing values, they can be imputed using a sub-model.</p></li>
<li><p>Models that use variance-type measures may benefit from coercing the distribution of some skewed predictors to be symmetric by estimating a transformation.</p></li>
</ul>
<p>Feature engineering and data preprocessing can also involve reformatting <em>required</em> by the model. Some models use geometric distance metrics and, consequently, numeric predictors should be centered and scaled so that they are all in the same units. Otherwise, the distance values would be biased by the scale of each column.</p>
<p>The <strong>recipes</strong> package combines different feature engineering and preprocessing tasks into a single object and then apply these transformations to different data sets.</p>
<div id="a-simple-recipe-for-the-ames-housing-data" class="section level3">
<h3>
<span class="header-section-number">10.3.1</span> A simple recipe for the Ames housing data</h3>
<p>In this section, we will focus on a small subset of the predictors available in the Ames housing data:</p>
<ul>
<li><p>The neighborhood (qualitative, with 29 neighborhoods in the training set)</p></li>
<li><p>The general living area (continuous, named <code>Gr_Liv_Area</code>)</p></li>
<li><p>The year built (<code>Year_Built</code>)</p></li>
<li><p>The type of building (<code>Bldg_Type</code> with values <code>OneFam</code> (<span class="math inline">\(n = 1,814\)</span>), <code>TwoFmCon</code> (<span class="math inline">\(n = 45\)</span>), <code>Duplex</code> (<span class="math inline">\(n = 76\)</span>), <code>Twnhs</code> (<span class="math inline">\(n = 76\)</span>), and <code>TwnhsE</code> (<span class="math inline">\(n = 188\)</span>))</p></li>
</ul>
<p>Suppose that an initial ordinary linear regression model were fit to these data. Recalling that, in Chapter <a href="model-choice.html#ames">10.1</a>, the sale prices were pre-logged, a standard call to <code>lm()</code>, a function similar to <code>stan_glm()</code>, might look like:</p>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb985-1"><a href="model-choice.html#cb985-1"></a><span class="kw">lm</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span><span class="kw">log10</span>(Gr_Liv_Area) <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type)</span></code></pre></div>
<p>When this function is executed, the data are converted from a data frame to a numeric <em>design matrix</em> (also called a <em>model matrix</em>) and then the least squares method is used to estimate parameters. What the formula above does can be decomposed into a series of <em>steps</em>:</p>
<ol style="list-style-type: decimal">
<li><p>Sale price is defined as the outcome while neighborhood, general living area, the year built, and building type variables are all defined as predictors.</p></li>
<li><p>A log transformation is applied to the general living area predictor.</p></li>
<li><p>The neighborhood and building type columns are converted from a non-numeric format to a numeric format (since least squares requires numeric predictors).</p></li>
</ol>
<p>The formula method will apply these data manipulations to any data, including new data, that are passed to the <code>predict()</code> function.</p>
<p>A recipe is also an object that defines a series of steps for data processing. Unlike the formula method inside a modeling function, the recipe defines the steps without immediately executing them; it is only a specification of what <em>should</em> be done. Here is a recipe equivalent to the formula above that builds on the code summary in Section <a href="#splitting-summary"><strong>??</strong></a>:</p>
<div class="sourceCode" id="cb986"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb986-1"><a href="model-choice.html#cb986-1"></a><span class="kw">library</span>(tidymodels) <span class="co"># Includes the recipes package</span></span>
<span id="cb986-2"><a href="model-choice.html#cb986-2"></a></span>
<span id="cb986-3"><a href="model-choice.html#cb986-3"></a>simple_ames &lt;-<span class="st"> </span></span>
<span id="cb986-4"><a href="model-choice.html#cb986-4"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type,</span>
<span id="cb986-5"><a href="model-choice.html#cb986-5"></a>         <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb986-6"><a href="model-choice.html#cb986-6"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb986-7"><a href="model-choice.html#cb986-7"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>())</span>
<span id="cb986-8"><a href="model-choice.html#cb986-8"></a>simple_ames</span></code></pre></div>
<pre><code>## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          4
## 
## Operations:
## 
## Log transformation on Gr_Liv_Area
## Dummy variables from all_nominal()</code></pre>
<p>Let’s break this down:</p>
<ol style="list-style-type: decimal">
<li><p>The call to <code>recipe()</code> with a formula tells the recipe the <em>roles</em> of the variables (e.g., predictor, outcome). It only uses the data to determine the data types for the columns.</p></li>
<li><p><code>step_log()</code> declares that <code>Gr_Liv_Area</code> should be log transformed.</p></li>
<li><p><code>step_dummy()</code> is used to specify which variables should be converted from a qualitative format to a quantitative format, in this case, using dummy or indicator variables. An indicator or dummy variable is a binary numeric variable (a column of ones and zeroes) that encodes qualitative information; we will dig deeper into these kinds of variables in Section <a href="model-choice.html#dummies">10.3.3</a>.</p></li>
</ol>
<p>The function <code>all_nominal()</code> captures the names of any columns that are currently factor or character (i.e., nominal) in nature. This is a <strong>dplyr</strong> selector function similar to <code>starts_with()</code> or <code>matches()</code> but can only be used inside of a recipe.</p>
<p>What is the advantage to using a recipe? There are a few, including:</p>
<ul>
<li><p>These computations can be recycled across models since they are not tightly coupled to the modeling function.</p></li>
<li><p>A recipe enables a broader set of data processing choices than formulas can offer.</p></li>
<li><p>The syntax can be very compact. For example, <code>all_nominal()</code> can be used to capture many variables for specific types of processing while a formula would require each to be explicitly listed.</p></li>
<li><p>All data processing can be captured in a single R object instead of in scripts that are repeated, or even spread across different files.</p></li>
</ul>
</div>
<div id="using-recipes" class="section level3">
<h3>
<span class="header-section-number">10.3.2</span> Using recipes</h3>
<p>Remember that when invoking the <code>recipe()</code> function, the steps are not estimated or executed in any way. The second phase for using a recipe is to estimate any quantities required by the steps using the <code>prep()</code> function. For example, we can use <code>step_normalize()</code> to center and scale any predictors selected in the step. When we call <code>prep(recipe, training)</code>, this function estimates the required means and standard deviations from the data in the <code>training</code> argument. The transformations specified by each step are also sequentially executed on the data set. Again using normalization as the example, the means and variances are estimated and then used to standardize the columns.</p>
<p>For our example recipe, we can now <code>prep()</code>:</p>
<div class="sourceCode" id="cb988"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb988-1"><a href="model-choice.html#cb988-1"></a>simple_ames &lt;-<span class="st"> </span><span class="kw">prep</span>(simple_ames, <span class="dt">training =</span> ames_train)</span>
<span id="cb988-2"><a href="model-choice.html#cb988-2"></a>simple_ames</span></code></pre></div>
<pre><code>## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          4
## 
## Training data contained 2199 data points and no missing data.
## 
## Operations:
## 
## Log transformation on Gr_Liv_Area [trained]
## Dummy variables from Neighborhood, Bldg_Type [trained]</code></pre>
<p>Note that, after preparing the recipe, the print statement shows the results of the selectors (e.g., <code>Neighborhood</code> and <code>Bldg_Type</code> are listed instead of <code>all_nominal</code>).</p>
<p>One important argument to <code>prep()</code> is <code>retain</code>. When <code>TRUE</code> (the default), the prepared version of the training set is kept within the recipe. This data set has been pre-processed using all of the steps listed in the recipe. Since <code>prep()</code> has to execute the recipe as it proceeds, it may be advantageous to keep this version of the training set so that, if that data set is to be used later, redundant calculations can be avoided. However, if the training set is big, it may be problematic to keep such a large amount of data in memory. Use <code>retain = FALSE</code> to avoid this.</p>
<p>The third phase of recipe usage is to apply the preprocessing operations to a data set using the <code>bake()</code> function. The <code>bake()</code> function can apply the recipe to <em>any</em> data set. To use the test set, the syntax would be:</p>
<!--DK: Fix the NULL problem!-->
<div class="sourceCode" id="cb990"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb990-1"><a href="model-choice.html#cb990-1"></a>test_ex &lt;-<span class="st"> </span><span class="kw">bake</span>(simple_ames, <span class="dt">new_data =</span> ames_test)</span>
<span id="cb990-2"><a href="model-choice.html#cb990-2"></a><span class="kw">names</span>(test_ex) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb990-3"><a href="model-choice.html#cb990-3"></a><span class="st">  </span><span class="kw">head</span>()</span></code></pre></div>
<p>Note the dummy variable columns starting with <code>Neighborhood_</code>. The <code>bake()</code> function can also take selectors so that, if we only wanted the neighborhood results, we could use:</p>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb991-1"><a href="model-choice.html#cb991-1"></a><span class="kw">bake</span>(simple_ames, ames_test, <span class="kw">starts_with</span>(<span class="st">"Neighborhood_"</span>))</span></code></pre></div>
<p>To get the processed version of the training set, we could use <code>bake()</code> and pass in the argument <code>ames_train</code> but, as previously mentioned, this would repeat calculations that have already been executed. Instead, we can use <code>new_data = NULL</code> to quickly return the training set (if <code>retain = TRUE</code> was used). It accesses the data component of the prepared recipe.</p>
<!-- DK: Why doesn't this work? NULL seems unacceptable. -->
<div class="sourceCode" id="cb992"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb992-1"><a href="model-choice.html#cb992-1"></a><span class="kw">bake</span>(simple_ames, <span class="dt">new_data =</span> <span class="ot">NULL</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb992-2"><a href="model-choice.html#cb992-2"></a><span class="st">  </span><span class="kw">nrow</span>()</span>
<span id="cb992-3"><a href="model-choice.html#cb992-3"></a></span>
<span id="cb992-4"><a href="model-choice.html#cb992-4"></a>ames_train <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb992-5"><a href="model-choice.html#cb992-5"></a><span class="st">  </span><span class="kw">nrow</span>()</span></code></pre></div>
<p>To reiterate, using a recipe is a three phase process summarized as:</p>
<p><img src="10-model-choice/images/recipes-process.svg"></p>
</div>
<div id="dummies" class="section level3">
<h3>
<span class="header-section-number">10.3.3</span> Encoding qualitative data in a numeric format</h3>
<p>One of the most common feature engineering tasks is transforming nominal or qualitative data (factors or characters) so that they can be encoded or represented numerically. Sometimes we can alter the factor levels of a qualitative column in helpful ways <em>prior</em> to such a transformation. For example, <code>step_unknown()</code> can be used to change missing values to a dedicated factor level. Similarly, if we anticipate that a new factor level may be encountered in future data, <code>step_novel()</code> can allot a new level for this purpose.</p>
<p>Additionally, <code>step_other()</code> can be used to analyze the frequencies of the factor levels in the training set and convert infrequently occurring values to a catch-all level of “other”, with a specific threshold that can be specified. A good example is the <code>Neighborhood</code> predictor in our data:</p>
<div class="sourceCode" id="cb993"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb993-1"><a href="model-choice.html#cb993-1"></a><span class="kw">ggplot</span>(ames_train, <span class="kw">aes</span>(<span class="dt">y =</span> Neighborhood)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb993-2"><a href="model-choice.html#cb993-2"></a><span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb993-3"><a href="model-choice.html#cb993-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="ot">NULL</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-819-1.png" width="672"></p>
<p>Here there are two neighborhoods that have less than five properties in the training data; in this case, no houses at all in the Landmark neighborhood were included in the training set. For some models, it may be problematic to have dummy variables with a single non-zero entry in the column. At a minimum, it is highly improbable that these features would be important to a model. If we add <code>step_other(Neighborhood, threshold = 0.01)</code> to our recipe, the bottom 1% of the neighborhoods will be lumped into a new level called “other”. In this training set, this will catch 9 neighborhoods.</p>
<p>For the Ames data, we can amend the recipe to use:</p>
<div class="sourceCode" id="cb994"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb994-1"><a href="model-choice.html#cb994-1"></a>simple_ames &lt;-<span class="st"> </span></span>
<span id="cb994-2"><a href="model-choice.html#cb994-2"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type,</span>
<span id="cb994-3"><a href="model-choice.html#cb994-3"></a>         <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb994-4"><a href="model-choice.html#cb994-4"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb994-5"><a href="model-choice.html#cb994-5"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb994-6"><a href="model-choice.html#cb994-6"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>())</span></code></pre></div>
<p>There are a few strategies for converting a factor predictor to a numeric format. The most common method is to create “dummy” or indicator variables. Let’s take the predictor in the Ames data for the building type, which is a factor variable with five levels. For dummy variables, the single <code>Bldg_Type</code> column would be replaced with four numeric columns whose values are either zero or one. These binary variables represent specific factor level values. In R, the convention is to <em>exclude</em> a column for the first factor level (<code>OneFam</code>, in this case). The <code>Bldg_Type</code> column would be replaced with a column called <code>TwoFmCon</code> that is one when the row has that value and zero otherwise. Three other columns are similarly created:</p>
<pre><code>## # A tibble: 5 x 5
##   `Raw Data` TwoFmCon Duplex Twnhs TwnhsE
##   &lt;fct&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1 OneFam            0      0     0      0
## 2 TwoFmCon          1      0     0      0
## 3 Duplex            0      1     0      0
## 4 Twnhs             0      0     1      0
## 5 TwnhsE            0      0     0      1</code></pre>
<p>Why not all five? The most basic reason is simplicity; if you know the value for these four columns, you can determine the last value because these are mutually exclusive categories. More technically, the classical justification is that a number of models, including ordinary linear regression, have numerical issues when there are linear dependencies between columns. If all five building type indicator columns are included, they would add up to the intercept column (if there is one). This would cause an issue, or perhaps an outright error, in the underlying matrix algebra.</p>
<p>The full set of encodings can be used for some models. This is traditionally called the “one-hot” encoding and can be achieved using the <code>one_hot</code> argument of <code>step_dummy()</code>.</p>
<p>One helpful feature of <code>step_dummy()</code> is that there is more control over how the resulting dummy variables are named. In base R, dummy variable names mash the variable name with the level, resulting in names like <code>NeighborhoodVeenker</code>. Recipes, by default, use an underscore as the separator between the name and level (e.g., <code>Neighborhood_Veenker</code>) and there is an option to use custom formatting for the names. The default naming convention in recipes makes it easier to capture those new columns in future steps using a selector, such as <code>starts_with("Neighborhood_")</code>.</p>
<p>Traditional dummy variables require that all of the possible categories be known to create a full set of numeric features. There are other methods for doing this transformation to a numeric format. <em>Feature hashing</em> methods only consider the value of the category to assign it to a predefined pool of dummy variables. This can be a good strategy when there are a large number of possible categories, but the statistical properties may not be optimal. For example, it may unnecessarily <em>alias</em> categories together (by assigning them to the same dummy variable). This reduces the specificity of the encoding and, if that dummy variable were important, it would be difficult to determine which of the categories is driving the effect.</p>
<p>Another method that is useful when there are a large number of categories is called <em>effect</em> or <em>likelihood encodings</em>. This method replaces the original data with a single numeric column that measures the <em>effect</em> of those data. For example, for the neighborhood predictor, the mean sale price is computed for each neighborhood and these means are substituted for the original data values. This can be effective but should be used with care. In effect, a mini-model is being added to the actual model and this can lead to over-fitting. To be cautious, this type of encoding should be rigorously resampled. Within a recipe, the <strong>embed</strong> package has several step functions, such as <code>step_lencode_mixed()</code>, for effect encodings. Both feature hashing and effect encoding methods can also seamlessly handle situations where a novel factor level is encountered in the data.</p>
<p>Different recipe steps can have different effects on columns of the data. For example, <code>step_log()</code> modifies a column in-place without changing the name. Other steps, such as <code>step_dummy()</code> eliminate the original data column and replace it with one or more columns with different names. This behavior depends on the type of operation being done.</p>
</div>
<div id="interaction-terms" class="section level3">
<h3>
<span class="header-section-number">10.3.4</span> Interaction terms</h3>
<p>Interaction effects involve two or more predictors. Such an effect occurs when one predictor has an effect on the outcome that is contingent on one or more other predictors. For example, if you were trying to predict your morning commute time, two potential predictors could be the amount of traffic and the time of day. However, the relationship between commute time and the amount of traffic is different for different times of day. In this case, you could add an interaction term between the two predictors to the model along with the original two predictors (which are called the “main effects”). Numerically, an interaction term between predictors is encoded as their product. Interactions are only defined in terms of their effect on the outcome and can be combinations of different types of data (e.g., numeric, categorical, etc).</p>
<p>After exploring the Ames training set, we might find that the regression slopes for the general living area differ for different building types:</p>
<div class="sourceCode" id="cb996"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb996-1"><a href="model-choice.html#cb996-1"></a><span class="kw">ggplot</span>(ames_train, <span class="kw">aes</span>(<span class="dt">x =</span> Gr_Liv_Area, <span class="dt">y =</span> <span class="dv">10</span><span class="op">^</span>Sale_Price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb996-2"><a href="model-choice.html#cb996-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">.2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb996-3"><a href="model-choice.html#cb996-3"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>Bldg_Type) <span class="op">+</span><span class="st"> </span></span>
<span id="cb996-4"><a href="model-choice.html#cb996-4"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">col =</span> <span class="st">"red"</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb996-5"><a href="model-choice.html#cb996-5"></a><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb996-6"><a href="model-choice.html#cb996-6"></a><span class="st">  </span><span class="kw">scale_y_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb996-7"><a href="model-choice.html#cb996-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"General Living Area"</span>, <span class="dt">y =</span> <span class="st">"Sale Price (USD)"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-822-1.png" width="672"></p>
<p>How are interactions specified? Recipes are explicit and sequential. With the current recipe, <code>step_dummy()</code> has already created dummy variables. How would we combine these for an interaction? The additional step would look like <code>step_interact(~ interaction terms)</code> where the terms on the right-hand side of the tilde are the interactions. These can include selectors, so it would be appropriate to use:</p>
<div class="sourceCode" id="cb997"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb997-1"><a href="model-choice.html#cb997-1"></a>simple_ames &lt;-<span class="st"> </span></span>
<span id="cb997-2"><a href="model-choice.html#cb997-2"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type,</span>
<span id="cb997-3"><a href="model-choice.html#cb997-3"></a>         <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb997-4"><a href="model-choice.html#cb997-4"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb997-5"><a href="model-choice.html#cb997-5"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb997-6"><a href="model-choice.html#cb997-6"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb997-7"><a href="model-choice.html#cb997-7"></a><span class="st">  </span><span class="co"># Gr_Liv_Area is on the log scale from a previous step</span></span>
<span id="cb997-8"><a href="model-choice.html#cb997-8"></a><span class="st">  </span><span class="kw">step_interact</span>( <span class="op">~</span><span class="st"> </span>Gr_Liv_Area<span class="op">:</span><span class="kw">starts_with</span>(<span class="st">"Bldg_Type_"</span>) )</span></code></pre></div>
<p>Additional interactions can be specified in this formula by separating them by <code>+</code>. Also note that the recipe will only utilize interactions between different variables; if the formula uses <code>var_1:var_1</code>, this term will be ignored.</p>
</div>
<div id="skip-equals-true" class="section level3">
<h3>
<span class="header-section-number">10.3.5</span> Skipping steps for new data</h3>
<p>The sale price data are already log transformed in the <code>ames</code> data frame. Why not use:</p>
<div class="sourceCode" id="cb998"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb998-1"><a href="model-choice.html#cb998-1"></a> <span class="kw">step_log</span>(Sale_Price, <span class="dt">base =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>This will cause a failure when the recipe is applied to new properties when the sale price is not known. Since price is what we are trying to predict, there probably won’t be a column in the data for this variable. In fact, to avoid <em>information leakage</em>, many tidymodels packages isolate the data being used when making any predictions. This means that the training set and any outcome columns are not available for use at prediction time.</p>
<p>However, there are other circumstances where this is not an adequate solution. For example, in classification models where there is a severe class imbalance, it is common to conduct <em>subsampling</em> of the data that are given to the modeling function. For example, suppose that there were two classes and a 10% event rate. A simple, albeit controversial, approach would be to <em>down-sample</em> the data so that the model is provided with all of the events and a random 10% of the non-event samples.</p>
<p>The problem is that the same subsampling process <strong>should not be applied</strong> to the data being predicted. As a result, when using a recipe, we need a mechanism to ensure that some operations are only applied to the data that are given to the model. Each step function has an option called <code>skip</code> that, when set to <code>TRUE</code>, will be ignored by the <code>bake()</code> function used with a data set argument. In this way, you can isolate the steps that affect the modeling data without causing errors when applied to new samples. However, all steps are applied when using <code>bake(new_data = NULL)</code>.</p>
</div>
<div id="spline-functions" class="section level3 unnumbered">
<h3>Spline functions</h3>
<p>When a predictor has a nonlinear relationship with the outcome, some types of predictive models can adaptively approximate this relationship during training. However, simpler is usually better and it is not uncommon to try to use a simple model, such as a linear fit, and add in specific non-linear features for predictors that may need them. One common method for doing this is to use <em>spline</em> functions to represent the data. Splines replace the existing numeric predictor with a set of columns that allow a model to emulate a flexible, non-linear relationship. As more spline terms are added to the data, the capacity to non-linearly represent the relationship increases. Unfortunately, it may also increase the likelihood of picking up on data trends that occur by chance (i.e., over-fitting).</p>
<p>If you have ever used <code>geom_smooth()</code> within a <code>ggplot</code>, you have probably used a spline representation of the data. For example, each panel below uses a different number of smooth splines for the latitude predictor:</p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb999-1"><a href="model-choice.html#cb999-1"></a><span class="kw">library</span>(patchwork)</span>
<span id="cb999-2"><a href="model-choice.html#cb999-2"></a><span class="kw">library</span>(splines)</span>
<span id="cb999-3"><a href="model-choice.html#cb999-3"></a></span>
<span id="cb999-4"><a href="model-choice.html#cb999-4"></a>plot_smoother &lt;-<span class="st"> </span><span class="cf">function</span>(deg_free) {</span>
<span id="cb999-5"><a href="model-choice.html#cb999-5"></a>  <span class="kw">ggplot</span>(ames_train, <span class="kw">aes</span>(<span class="dt">x =</span> Latitude, <span class="dt">y =</span> Sale_Price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb999-6"><a href="model-choice.html#cb999-6"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">.2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb999-7"><a href="model-choice.html#cb999-7"></a><span class="st">    </span><span class="kw">scale_y_log10</span>() <span class="op">+</span></span>
<span id="cb999-8"><a href="model-choice.html#cb999-8"></a><span class="st">    </span><span class="kw">geom_smooth</span>(</span>
<span id="cb999-9"><a href="model-choice.html#cb999-9"></a>      <span class="dt">method =</span> lm,</span>
<span id="cb999-10"><a href="model-choice.html#cb999-10"></a>      <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(x, <span class="dt">df =</span> deg_free),</span>
<span id="cb999-11"><a href="model-choice.html#cb999-11"></a>      <span class="dt">col =</span> <span class="st">"red"</span>,</span>
<span id="cb999-12"><a href="model-choice.html#cb999-12"></a>      <span class="dt">se =</span> <span class="ot">FALSE</span></span>
<span id="cb999-13"><a href="model-choice.html#cb999-13"></a>    ) <span class="op">+</span></span>
<span id="cb999-14"><a href="model-choice.html#cb999-14"></a><span class="st">    </span><span class="kw">ggtitle</span>(<span class="kw">paste</span>(deg_free, <span class="st">"Spline Terms"</span>))</span>
<span id="cb999-15"><a href="model-choice.html#cb999-15"></a>}</span>
<span id="cb999-16"><a href="model-choice.html#cb999-16"></a></span>
<span id="cb999-17"><a href="model-choice.html#cb999-17"></a>( <span class="kw">plot_smoother</span>(<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">plot_smoother</span>(<span class="dv">5</span>) ) <span class="op">/</span><span class="st"> </span>( <span class="kw">plot_smoother</span>(<span class="dv">20</span>) <span class="op">+</span><span class="st"> </span><span class="kw">plot_smoother</span>(<span class="dv">100</span>) )</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-824-1.png" width="672"></p>
<p>The <code>ns()</code> function in the <strong>splines</strong> package generates feature columns using functions called <em>natural splines</em>.</p>
<p>Some panels clearly fit poorly; two terms <em>under-fit</em> the data while 100 terms <em>over-fit</em>. The panels with five and 20 terms seem like reasonably smooth fits that catch the main patterns of the data. This indicates that the proper amount of “non-linear-ness” matters. The number of spline terms could then be considered a <em>tuning parameter</em> for this model.</p>
<p>In <strong>recipes</strong>, there are multiple steps that can create these types of terms. To add a natural spline representation for this predictor:</p>
<div class="sourceCode" id="cb1000"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1000-1"><a href="model-choice.html#cb1000-1"></a><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type <span class="op">+</span><span class="st"> </span>Latitude,</span>
<span id="cb1000-2"><a href="model-choice.html#cb1000-2"></a>         <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb1000-3"><a href="model-choice.html#cb1000-3"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1000-4"><a href="model-choice.html#cb1000-4"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1000-5"><a href="model-choice.html#cb1000-5"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1000-6"><a href="model-choice.html#cb1000-6"></a><span class="st">  </span><span class="kw">step_interact</span>( <span class="op">~</span><span class="st"> </span>Gr_Liv_Area<span class="op">:</span><span class="kw">starts_with</span>(<span class="st">"Bldg_Type_"</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1000-7"><a href="model-choice.html#cb1000-7"></a><span class="st">  </span><span class="kw">step_ns</span>(Latitude, <span class="dt">deg_free =</span> <span class="dv">20</span>)</span></code></pre></div>
<p>The user would need to determine if both neighborhood and latitude should be in the model since they both represent the same underlying data in different ways.</p>
</div>
<div id="how-data-are-used-by-the-recipe" class="section level3">
<h3>
<span class="header-section-number">10.3.6</span> How data are used by the recipe</h3>
<p>Data are given to recipes at different stages. When calling <code>recipe(..., data)</code>, the data set is used to determine the data types of each column so that selectors such as <code>all_numeric()</code> can be used. When preparing the data using <code>prep(recipe, training)</code>, the data in <code>training</code> are used for all estimation operations, from determining factor levels to computing PCA components and everything in between. It is important to realize that all preprocessing and feature engineering steps only utilize the training data. Otherwise, information leakage can negatively impact the model.</p>
<p>When using <code>bake(recipe, new_data)</code>, no quantities are re-estimated using the values in <code>new_data</code>. Take centering and scaling using <code>step_normalize()</code> as an example. Using this step, the means and standard deviations from the appropriate columns are determined from the training set; new samples are standardized using these values when <code>bake()</code> is invoked.</p>
</div>
<div id="recipes-manual" class="section level3">
<h3>
<span class="header-section-number">10.3.7</span> Using a recipe with traditional modeling functions</h3>
<p>Previously, we introduced high-level interfaces that take a recipe as an input argument and automatically handle the <code>prep()</code>/<code>bake()</code> process of preparing data for modeling. However, recipes can be used with traditional R modeling functions as well; this section shows how to use a recipe outside those high-level interfaces.</p>
<p>Let’s use a slightly augmented version of the last recipe, now including longitude:</p>
<div class="sourceCode" id="cb1001"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1001-1"><a href="model-choice.html#cb1001-1"></a>ames_rec &lt;-<span class="st"> </span></span>
<span id="cb1001-2"><a href="model-choice.html#cb1001-2"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type <span class="op">+</span><span class="st"> </span></span>
<span id="cb1001-3"><a href="model-choice.html#cb1001-3"></a><span class="st">           </span>Latitude <span class="op">+</span><span class="st"> </span>Longitude, <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb1001-4"><a href="model-choice.html#cb1001-4"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1001-5"><a href="model-choice.html#cb1001-5"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1001-6"><a href="model-choice.html#cb1001-6"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1001-7"><a href="model-choice.html#cb1001-7"></a><span class="st">  </span><span class="kw">step_interact</span>( <span class="op">~</span><span class="st"> </span>Gr_Liv_Area<span class="op">:</span><span class="kw">starts_with</span>(<span class="st">"Bldg_Type_"</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1001-8"><a href="model-choice.html#cb1001-8"></a><span class="st">  </span><span class="kw">step_ns</span>(Latitude, Longitude, <span class="dt">deg_free =</span> <span class="dv">20</span>)</span></code></pre></div>
<p>To get the recipe ready, we prepare it, and then extract the training set using <code>bake()</code> with <code>new_data = NULL</code>. When calling <code>prep()</code>, if the <code>training</code> argument is not given, it uses the data that was initially given to the <code>recipe()</code> function call.</p>
<!-- DK: Third NULL error. -->
<div class="sourceCode" id="cb1002"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1002-1"><a href="model-choice.html#cb1002-1"></a>ames_rec_prepped &lt;-<span class="st"> </span><span class="kw">prep</span>(ames_rec)</span>
<span id="cb1002-2"><a href="model-choice.html#cb1002-2"></a><span class="co"># ames_train_prepped &lt;- bake(ames_rec_prepped, new_data = NULL)</span></span>
<span id="cb1002-3"><a href="model-choice.html#cb1002-3"></a>ames_test_prepped &lt;-<span class="st"> </span><span class="kw">bake</span>(ames_rec_prepped, ames_test)</span>
<span id="cb1002-4"><a href="model-choice.html#cb1002-4"></a></span>
<span id="cb1002-5"><a href="model-choice.html#cb1002-5"></a><span class="co"># Fit the model; Note that the column Sale_Price has already been</span></span>
<span id="cb1002-6"><a href="model-choice.html#cb1002-6"></a><span class="co"># log transformed.</span></span>
<span id="cb1002-7"><a href="model-choice.html#cb1002-7"></a></span>
<span id="cb1002-8"><a href="model-choice.html#cb1002-8"></a><span class="co"># lm_fit &lt;- lm(Sale_Price ~ ., data = ames_train_prepped)</span></span></code></pre></div>
<p>The <strong>broom</strong> package has methods that make it easier to work with model objects. First, <code>broom::glance()</code> shows a succinct summary of the model in a handy tibble format:</p>
<div class="sourceCode" id="cb1003"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1003-1"><a href="model-choice.html#cb1003-1"></a><span class="co"># glance(lm_fit)</span></span></code></pre></div>
<p>The model coefficients can be extracted using the <code>tidy()</code> method:</p>
<div class="sourceCode" id="cb1004"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1004-1"><a href="model-choice.html#cb1004-1"></a><span class="co"># tidy(lm_fit)</span></span></code></pre></div>
<p>To make predictions on the test set, we use the standard syntax:</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1005-1"><a href="model-choice.html#cb1005-1"></a><span class="co"># predict(lm_fit, ames_test_prepped %&gt;% </span></span>
<span id="cb1005-2"><a href="model-choice.html#cb1005-2"></a><span class="co">#           head())</span></span></code></pre></div>
</div>
<div id="tidy-a-recipe" class="section level3">
<h3>
<span class="header-section-number">10.3.8</span> Tidy a recipe</h3>
<p>There is also a <code>tidy()</code> method for recipes. Calling it with no other arguments gives a summary of the recipe steps:</p>
<div class="sourceCode" id="cb1006"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1006-1"><a href="model-choice.html#cb1006-1"></a><span class="kw">tidy</span>(ames_rec_prepped)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 6
##   number operation type     trained skip  id            
##    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;         
## 1      1 step      log      TRUE    FALSE log_Rh9Lx     
## 2      2 step      other    TRUE    FALSE other_pkwDF   
## 3      3 step      dummy    TRUE    FALSE dummy_ARVoa   
## 4      4 step      interact TRUE    FALSE interact_1RjvP
## 5      5 step      ns       TRUE    FALSE ns_JOyD5</code></pre>
<p>We can specify the <code>id</code> field in a step function call but otherwise it is generated using a random suffix. This field can be helpful if the same type of step is added to the recipe more than once. Let’s specify the <code>id</code> ahead of time for <code>step_log()</code>, since we want to <code>tidy()</code> it:</p>
<div class="sourceCode" id="cb1008"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1008-1"><a href="model-choice.html#cb1008-1"></a>ames_rec &lt;-<span class="st"> </span></span>
<span id="cb1008-2"><a href="model-choice.html#cb1008-2"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type <span class="op">+</span><span class="st"> </span></span>
<span id="cb1008-3"><a href="model-choice.html#cb1008-3"></a><span class="st">           </span>Latitude <span class="op">+</span><span class="st"> </span>Longitude, <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb1008-4"><a href="model-choice.html#cb1008-4"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>, <span class="dt">id =</span> <span class="st">"my_id"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1008-5"><a href="model-choice.html#cb1008-5"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1008-6"><a href="model-choice.html#cb1008-6"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1008-7"><a href="model-choice.html#cb1008-7"></a><span class="st">  </span><span class="kw">step_interact</span>( <span class="op">~</span><span class="st"> </span>Gr_Liv_Area<span class="op">:</span><span class="kw">starts_with</span>(<span class="st">"Bldg_Type_"</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1008-8"><a href="model-choice.html#cb1008-8"></a><span class="st">  </span><span class="kw">step_ns</span>(Latitude, Longitude, <span class="dt">deg_free =</span> <span class="dv">20</span>)</span>
<span id="cb1008-9"><a href="model-choice.html#cb1008-9"></a></span>
<span id="cb1008-10"><a href="model-choice.html#cb1008-10"></a>ames_rec_prepped &lt;-<span class="st"> </span><span class="kw">prep</span>(ames_rec)</span></code></pre></div>
<p>The <code>tidy()</code> method can be called again along with the <code>id</code> identifier we specified to get these results:</p>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1009-1"><a href="model-choice.html#cb1009-1"></a><span class="kw">tidy</span>(ames_rec_prepped, <span class="dt">id =</span> <span class="st">"my_id"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   terms        base id   
##   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;
## 1 Gr_Liv_Area    10 my_id</code></pre>
<p>The <code>tidy()</code> method can be called with the <code>number</code> identifier as well, if we know which step in the recipe we need:</p>
<div class="sourceCode" id="cb1011"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1011-1"><a href="model-choice.html#cb1011-1"></a><span class="kw">tidy</span>(ames_rec_prepped, <span class="dt">number =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## # A tibble: 20 x 3
##    terms        retained                                id         
##    &lt;chr&gt;        &lt;chr&gt;                                   &lt;chr&gt;      
##  1 Neighborhood North_Ames                              other_ZKAis
##  2 Neighborhood College_Creek                           other_ZKAis
##  3 Neighborhood Old_Town                                other_ZKAis
##  4 Neighborhood Edwards                                 other_ZKAis
##  5 Neighborhood Somerset                                other_ZKAis
##  6 Neighborhood Northridge_Heights                      other_ZKAis
##  7 Neighborhood Gilbert                                 other_ZKAis
##  8 Neighborhood Sawyer                                  other_ZKAis
##  9 Neighborhood Northwest_Ames                          other_ZKAis
## 10 Neighborhood Sawyer_West                             other_ZKAis
## 11 Neighborhood Mitchell                                other_ZKAis
## 12 Neighborhood Brookside                               other_ZKAis
## 13 Neighborhood Crawford                                other_ZKAis
## 14 Neighborhood Iowa_DOT_and_Rail_Road                  other_ZKAis
## 15 Neighborhood Timberland                              other_ZKAis
## 16 Neighborhood Northridge                              other_ZKAis
## 17 Neighborhood Stone_Brook                             other_ZKAis
## 18 Neighborhood South_and_West_of_Iowa_State_University other_ZKAis
## 19 Neighborhood Clear_Creek                             other_ZKAis
## 20 Neighborhood Meadow_Village                          other_ZKAis</code></pre>
<p>Each <code>tidy()</code> method returns the relevant information about that step. For example, the <code>tidy()</code> method for <code>step_dummy()</code> returns a column with the variables that were converted to dummy variables and another column with all of the known levels for each column.</p>
</div>
<div id="column-roles" class="section level3">
<h3>
<span class="header-section-number">10.3.9</span> Column roles</h3>
<p>When a formula is used with the initial call to <code>recipes()</code> it assigns <em>roles</em> to each of the column depending on which side of the tilde that they are on. Those roles are either <code>"predictor"</code> or <code>"outcome"</code>. However, other roles can be assigned as needed.</p>
<p>For example, in our Ames data set, the original raw data contained a field for address. It may be useful to keep that column in the data so that, after predictions are made, problematic results can be investigated in detail. In other words, the column is important but isn’t a predictor or outcome.</p>
<p>To solve this, the <code>add_role()</code>, <code>remove_role()</code>, and <code>update_role()</code> functions can be helpful. For example, for the house price data, the street address column could be modified using</p>
<div class="sourceCode" id="cb1013"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1013-1"><a href="model-choice.html#cb1013-1"></a>ames_rec <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">update_role</span>(address, <span class="dt">new_role =</span> <span class="st">"street address"</span>)</span></code></pre></div>
<p>Any character string can be used as a role. Also, columns can have multiple roles so that they can be selected under more than one context.</p>
<p>This can be helpful when the data are <em>resampled</em>. It helps to keep the columns that are <em>not</em> involved with the model fit in the same data frame (rather than in an external vector). Resampling creates alternate versions of the data mostly by row subsampling. If the street address were in another column, additional subsampling would be required and might lead to more complex code and a higher likelihood of errors.</p>
<p>Finally, all step functions have a <code>role</code> field that can assign roles to the results of the step. In many cases, columns affected by a step retain their existing role. For example, the <code>step_log()</code> calls to the <code>ames_rec</code> object above affected the <code>Gr_Liv_Area</code> column. For that step, the default behavior is to keep the existing role for this column since no new column is created. As a counter-example, the step to produce splines defaults new columns to have a role of <code>"predictor"</code> since that is usually how spline columns are used in a model. Most steps have sensible defaults but, since the defaults can be different, be sure to check the documentation page to understand what which role(s) will be assigned.</p>
<p>You have learned about using recipes for flexible feature engineering and data preprocessing, from creating dummy variables to handling class imbalance and more. Feature engineering is an important part of the modeling process where information leakage can easily occur and good practices must be adopted. Between the <strong>recipes</strong> package and other packages that extend recipes, there are over 100 available steps. All possible recipe steps are enumerated at <a href="https://www.tidymodels.org/find/"><code>tidymodels.org/find</code></a>. The recipes framework provides a rich data manipulation environment for preprocessing and transforming data prior to modeling.
Additionally, <a href="https://www.tidymodels.org/learn/develop/recipes/"><code>tidymodels.org/learn/develop/recipes/</code></a> shows how custom steps can be created.</p>
<p>The code that we will use in later is:</p>
<div class="sourceCode" id="cb1014"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1014-1"><a href="model-choice.html#cb1014-1"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb1014-2"><a href="model-choice.html#cb1014-2"></a><span class="kw">data</span>(ames)</span>
<span id="cb1014-3"><a href="model-choice.html#cb1014-3"></a>ames &lt;-<span class="st"> </span><span class="kw">mutate</span>(ames, <span class="dt">Sale_Price =</span> <span class="kw">log10</span>(Sale_Price))</span>
<span id="cb1014-4"><a href="model-choice.html#cb1014-4"></a></span>
<span id="cb1014-5"><a href="model-choice.html#cb1014-5"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1014-6"><a href="model-choice.html#cb1014-6"></a>ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ames, <span class="dt">prob =</span> <span class="fl">0.80</span>, <span class="dt">strata =</span> Sale_Price)</span>
<span id="cb1014-7"><a href="model-choice.html#cb1014-7"></a>ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)</span>
<span id="cb1014-8"><a href="model-choice.html#cb1014-8"></a>ames_test  &lt;-<span class="st">  </span><span class="kw">testing</span>(ames_split)</span>
<span id="cb1014-9"><a href="model-choice.html#cb1014-9"></a></span>
<span id="cb1014-10"><a href="model-choice.html#cb1014-10"></a>ames_rec &lt;-<span class="st"> </span></span>
<span id="cb1014-11"><a href="model-choice.html#cb1014-11"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type <span class="op">+</span><span class="st"> </span></span>
<span id="cb1014-12"><a href="model-choice.html#cb1014-12"></a><span class="st">           </span>Latitude <span class="op">+</span><span class="st"> </span>Longitude, <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb1014-13"><a href="model-choice.html#cb1014-13"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1014-14"><a href="model-choice.html#cb1014-14"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1014-15"><a href="model-choice.html#cb1014-15"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1014-16"><a href="model-choice.html#cb1014-16"></a><span class="st">  </span><span class="kw">step_interact</span>( <span class="op">~</span><span class="st"> </span>Gr_Liv_Area<span class="op">:</span><span class="kw">starts_with</span>(<span class="st">"Bldg_Type_"</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1014-17"><a href="model-choice.html#cb1014-17"></a><span class="st">  </span><span class="kw">step_ns</span>(Latitude, Longitude, <span class="dt">deg_free =</span> <span class="dv">20</span>)</span></code></pre></div>
</div>
</div>
<div id="models" class="section level2">
<h2>
<span class="header-section-number">10.4</span> Fitting models with parsnip</h2>
<p>The <strong>parsnip</strong> package provides a fluent and standardized interface for a variety of different models. In this chapter, we both give some motivation for why a common interface is beneficial and show how the use the package.</p>
<p>In Chapter <a href="model-choice.html#recipes">10.3</a>, we discussed recipe objects for feature engineering and data preprocessing prior to modeling. Recipes are not discussed in this chapter in order to focus on the model itself; Chapter <a href="#workflows"><strong>??</strong></a> illustrates how to combine models and recipes together into something called a <code>workflow</code> object.</p>
<div id="create-a-model" class="section level3">
<h3>
<span class="header-section-number">10.4.1</span> Create a model</h3>
<p>Once the data have been encoded in a format ready for a modeling algorithm, such as a numeric matrix, they can be used in the model building process.</p>
<p>Suppose that a linear regression model was our initial choice for the model. This is equivalent to specifying that the outcome data is numeric and that the predictors are related to the model in terms of simple slopes and intercepts:</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_{1i} + \ldots + \beta_p x_{pi}\]</span></p>
<p>There are a variety of methods that can be used to estimate the model parameters:</p>
<ul>
<li><p><em>Ordinary linear regression</em> uses the traditional method of least squares to solve for the model parameters.</p></li>
<li><p><em>Regularized linear regression</em> adds a penalty to the least squares method to encourage simplicity by removing predictors and/or shrinking their coefficients towards zero. This can be executed using Bayesian or non-Bayesian techniques.</p></li>
</ul>
<p>In R, the <strong>stats</strong> package can be used for the first case. The syntax for <code>lm()</code> is</p>
<div class="sourceCode" id="cb1015"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1015-1"><a href="model-choice.html#cb1015-1"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(formula, data, ...)</span></code></pre></div>
<p>where <code>...</code> symbolizes other options to pass to <code>lm()</code>. The function does <em>not</em> have an <code>x</code>/<code>y</code> interface, where we might pass in our outcome as <code>y</code> and our predictors as <code>x</code>.</p>
<p>To estimate with regularization, a Bayesian model can be fit using the <strong>rstanarm</strong> package:</p>
<div class="sourceCode" id="cb1016"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1016-1"><a href="model-choice.html#cb1016-1"></a>model &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(formula, data, <span class="dt">family =</span> <span class="st">"gaussian"</span>, ...)</span></code></pre></div>
<p>A popular non-Bayesian approach to regularized regression is the glmnet model. Its syntax is:</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1017-1"><a href="model-choice.html#cb1017-1"></a>model &lt;-<span class="st"> </span><span class="kw">glmnet</span>(<span class="dt">x =</span> matrix, <span class="dt">y =</span> vector, <span class="dt">family =</span> <span class="st">"gaussian"</span>, ...)</span></code></pre></div>
<p>In this case, the predictor data must already be formatted into a numeric matrix; there is only and <code>x</code>/<code>y</code> method and no formula method.</p>
<p>Note that these interfaces are heterogeneous in either how the data are passed to the model function or in terms of their arguments. The first issue is that, to fit models across different packages, the data must be formatted in different ways. <code>lm()</code> and <code>stan_glm()</code> only have formula interfaces while <code>glmnet()</code> does not. For other types of models, the interfaces may be even more disparate. For a person trying to do data analysis, these differences require the memorization of each package’s syntax and can be very frustrating.</p>
<p>For tidymodels, the approach to specifying a model is intended to be more unified:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Specify the <em>type</em> of model based on its mathematical structure</strong> (e.g., linear regression, random forest, <em>K</em>-nearest neighbors, etc).</p></li>
<li><p><strong>Specify the <em>engine</em> for fitting the model.</strong> Most often this reflects the software package that should be used.</p></li>
<li><p><strong>When required, declare the <em>mode</em> of the model.</strong> The mode reflects the type of prediction outcome. For numeric outcomes, the mode is <em>regression</em>; for qualitative outcomes, it is <em>classification</em><label for="tufte-sn-12" class="margin-toggle sidenote-number">12</label><input type="checkbox" id="tufte-sn-12" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">12</span> Note that <strong>parsnip</strong> constrains the outcome column of a classification models to be encoded as a <em>factor</em>; using binary numeric values will result in an error.</span>. If a model can only create one type of model, such as linear regression, the mode is already set.</p></li>
</ol>
<p>These specifications are built <em>without referencing the data</em>. For example, for the three cases above:</p>
<div class="sourceCode" id="cb1018"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1018-1"><a href="model-choice.html#cb1018-1"></a><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>)</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: lm</code></pre>
<div class="sourceCode" id="cb1020"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1020-1"><a href="model-choice.html#cb1020-1"></a><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">set_engine</span>(<span class="st">"glmnet"</span>) </span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: glmnet</code></pre>
<div class="sourceCode" id="cb1022"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1022-1"><a href="model-choice.html#cb1022-1"></a><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">set_engine</span>(<span class="st">"stan"</span>)</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: stan</code></pre>
<p>Once the details of the model have been specified, the model estimation can be done with either the <code>fit()</code> function (to use a formula) or the <code>fit_xy()</code> function (when your data are already pre-processed). The <strong>parsnip</strong> package allows the user to be indifferent to the interface of the underlying model; you can always use a formula even if the modeling package’s function only has the <code>x</code>/<code>y</code> interface.</p>
<p>The <code>translate()</code> function can provide details on how <strong>parsnip</strong> converts the user’s code to the package’s syntax:</p>
<div class="sourceCode" id="cb1024"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1024-1"><a href="model-choice.html#cb1024-1"></a><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1024-2"><a href="model-choice.html#cb1024-2"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1024-3"><a href="model-choice.html#cb1024-3"></a><span class="st">  </span><span class="kw">translate</span>()</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: lm 
## 
## Model fit template:
## stats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())</code></pre>
<div class="sourceCode" id="cb1026"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1026-1"><a href="model-choice.html#cb1026-1"></a><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1026-2"><a href="model-choice.html#cb1026-2"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"glmnet"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1026-3"><a href="model-choice.html#cb1026-3"></a><span class="st">  </span><span class="kw">translate</span>()</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: glmnet 
## 
## Model fit template:
## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
##     family = "gaussian")</code></pre>
<div class="sourceCode" id="cb1028"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1028-1"><a href="model-choice.html#cb1028-1"></a><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1028-2"><a href="model-choice.html#cb1028-2"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"stan"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1028-3"><a href="model-choice.html#cb1028-3"></a><span class="st">  </span><span class="kw">translate</span>()</span></code></pre></div>
<pre><code>## Linear Regression Model Specification (regression)
## 
## Computational engine: stan 
## 
## Model fit template:
## rstanarm::stan_glm(formula = missing_arg(), data = missing_arg(), 
##     weights = missing_arg(), family = stats::gaussian, refresh = 0)</code></pre>
<p>Note that <code>missing_arg()</code> is just a placeholder for the data that has yet to be provided.</p>
<p>Let’s walk through how to predict the sale price of houses in the Ames data as a function of only longitude and latitude.</p>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1030-1"><a href="model-choice.html#cb1030-1"></a>lm_model &lt;-<span class="st"> </span></span>
<span id="cb1030-2"><a href="model-choice.html#cb1030-2"></a><span class="st">  </span><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1030-3"><a href="model-choice.html#cb1030-3"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>)</span>
<span id="cb1030-4"><a href="model-choice.html#cb1030-4"></a></span>
<span id="cb1030-5"><a href="model-choice.html#cb1030-5"></a><span class="co"># Recall that Sale_Price has been pre-logged</span></span>
<span id="cb1030-6"><a href="model-choice.html#cb1030-6"></a></span>
<span id="cb1030-7"><a href="model-choice.html#cb1030-7"></a>lm_form_fit &lt;-<span class="st"> </span></span>
<span id="cb1030-8"><a href="model-choice.html#cb1030-8"></a><span class="st">  </span>lm_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1030-9"><a href="model-choice.html#cb1030-9"></a><span class="st">  </span><span class="kw">fit</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Longitude <span class="op">+</span><span class="st"> </span>Latitude, <span class="dt">data =</span> ames_train)</span>
<span id="cb1030-10"><a href="model-choice.html#cb1030-10"></a></span>
<span id="cb1030-11"><a href="model-choice.html#cb1030-11"></a>lm_xy_fit &lt;-<span class="st"> </span></span>
<span id="cb1030-12"><a href="model-choice.html#cb1030-12"></a><span class="st">  </span>lm_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1030-13"><a href="model-choice.html#cb1030-13"></a><span class="st">  </span><span class="kw">fit_xy</span>(<span class="dt">x =</span> ames_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(Longitude, Latitude),</span>
<span id="cb1030-14"><a href="model-choice.html#cb1030-14"></a>         <span class="dt">y =</span> ames_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(Sale_Price))</span>
<span id="cb1030-15"><a href="model-choice.html#cb1030-15"></a>    </span>
<span id="cb1030-16"><a href="model-choice.html#cb1030-16"></a>lm_form_fit</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  3ms 
## 
## Call:
## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)
## 
## Coefficients:
## (Intercept)    Longitude     Latitude  
##     -316.37        -2.08         3.01</code></pre>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="model-choice.html#cb1032-1"></a>lm_xy_fit</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  3ms 
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
## (Intercept)    Longitude     Latitude  
##     -316.37        -2.08         3.01</code></pre>
<p>Not only does <strong>parsnip</strong> enable a consistent model interface for different packages, it also provides consistency in the <em>model arguments</em>. It is common for different functions which fit the same model to have different argument names. Random forest model functions are a good example. Three commonly used arguments are the number of trees in the ensemble, the number of predictors to randomly sample with each split within a tree, and the number of data points required to make a split. For three different R packages implementing this algorithm, those arguments are:</p>
<p>In an effort to make argument specification less painful, <strong>parsnip</strong> uses common argument names within and between packages. For random forests, <strong>parsnip</strong> models use:</p>
<p>Admittedly, this is one more set of arguments to memorize. However, when other types of models have the same argument types, these names still apply. For example, boosted tree ensembles also create a large number of tree-based models, so <code>trees</code> is also used there, as is <code>num_n</code>, and so on. The <strong>parsnip</strong> argument names have also been standardized with similar recipe arguments.</p>
<p>Some of the original argument names can be fairly jargon-y. For example, to specify the amount of regularization to use in a glmnet model, the Greek letter <code>lambda</code> is used. While this mathematical notation is commonly used in the statistics literature, it is not obvious to many people what <code>lambda</code> represents (especially those who consume the model results). Since this is the penalty used in regularization, <strong>parsnip</strong> standardizes on the argument name <code>penalty</code>. Similarly, the number of neighbors in a <em>K</em>-nearest neighbors model is called <code>neighbors</code> instead of <code>k</code>. Our rule of thumb when standardizing argument names is:</p>
<blockquote>
<p>If a practitioner were to include these names in a plot or table, would the people viewing those results understand the name?</p>
</blockquote>
<p>To understand how the <strong>parsnip</strong> argument names map to the original names, use the help file for the model (available via <code>?rand_forest</code>) as well as the <code>translate()</code> function:</p>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="model-choice.html#cb1034-1"></a><span class="kw">rand_forest</span>(<span class="dt">trees =</span> <span class="dv">1000</span>, <span class="dt">min_n =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1034-2"><a href="model-choice.html#cb1034-2"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"ranger"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1034-3"><a href="model-choice.html#cb1034-3"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1034-4"><a href="model-choice.html#cb1034-4"></a><span class="st">  </span><span class="kw">translate</span>()</span></code></pre></div>
<pre><code>## Random Forest Model Specification (regression)
## 
## Main Arguments:
##   trees = 1000
##   min_n = 5
## 
## Computational engine: ranger 
## 
## Model fit template:
## ranger::ranger(formula = missing_arg(), data = missing_arg(), 
##     case.weights = missing_arg(), num.trees = 1000, min.node.size = 5, 
##     num.threads = 1, verbose = FALSE, seed = sample.int(10^5, 
##         1))</code></pre>
<p>Modeling functions in <strong>parsnip</strong> separate model arguments into two categories:</p>
<ul>
<li><p><em>Main arguments</em> are more commonly used and tend to be available across engines.</p></li>
<li><p><em>Engine arguments</em> are either specific to a particular engine or used more rarely.</p></li>
</ul>
<p>For example, in the translation of the random forest code above, the arguments <code>num.threads</code>, <code>verbose</code>, and <code>seed</code> were added by default. These arguments are specific to the ranger implementation of random forest models and wouldn’t make sense as main arguments. Engine-specific arguments can be specified in <code>set_engine()</code>. For example, to have the <code>ranger::ranger()</code> function print out more information about the fit:</p>
<div class="sourceCode" id="cb1036"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1036-1"><a href="model-choice.html#cb1036-1"></a><span class="kw">rand_forest</span>(<span class="dt">trees =</span> <span class="dv">1000</span>, <span class="dt">min_n =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1036-2"><a href="model-choice.html#cb1036-2"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"ranger"</span>, <span class="dt">verbose =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1036-3"><a href="model-choice.html#cb1036-3"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>) </span></code></pre></div>
<pre><code>## Random Forest Model Specification (regression)
## 
## Main Arguments:
##   trees = 1000
##   min_n = 5
## 
## Engine-Specific Arguments:
##   verbose = TRUE
## 
## Computational engine: ranger</code></pre>
</div>
<div id="use-the-model-results" class="section level3">
<h3>
<span class="header-section-number">10.4.2</span> Use the model results</h3>
<p>Once the model is created and fit, we can use the results in a variety of ways; we might want to plot, print, or otherwise examine the model output. Several quantities are stored in a <strong>parsnip</strong> model object, including the fitted model. This can be found in an element called <code>fit</code>, which can be returned using the <code>purrr::pluck()</code> function:</p>
<!-- DK: Investigate pluck nonsense. -->
<div class="sourceCode" id="cb1038"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1038-1"><a href="model-choice.html#cb1038-1"></a>lm_form_fit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1038-2"><a href="model-choice.html#cb1038-2"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">pluck</span>(<span class="st">"fit"</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)
## 
## Coefficients:
## (Intercept)    Longitude     Latitude  
##     -316.37        -2.08         3.01</code></pre>
<p>Normal methods can be applied to this object, such as printing, plotting, and so on.</p>
<p>One issue with some existing methods in base R is that the results are stored in a manner that may not be the most useful. As a solution, the <strong>broom</strong> package has methods to convert many types of model objects to a tidy structure. For example, using the <code>tidy()</code> method on the linear model produces:</p>
<div class="sourceCode" id="cb1040"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1040-1"><a href="model-choice.html#cb1040-1"></a><span class="kw">tidy</span>(lm_form_fit)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)  -316.      14.9       -21.2 3.04e-91
## 2 Longitude      -2.08     0.133     -15.6 3.21e-52
## 3 Latitude        3.01     0.185      16.3 2.58e-56</code></pre>
<p>The column names are standardized across models and do not contain any additional data (such as the type of statistical test). The data previously contained in the row names are now in a column called <code>terms</code> and so on. One important principle in the tidymodels ecosystem is that a function should return values that are <em>predictable, consistent, and unsurprising</em>.</p>
</div>
<div id="parsnip-predictions" class="section level3">
<h3>
<span class="header-section-number">10.4.3</span> Make predictions</h3>
<p>Another area where <strong>parsnip</strong> diverges from conventional R modeling functions is the format of values returned from <code>predict()</code>. For predictions, <strong>parsnip</strong> always conforms to the following rules:</p>
<ol style="list-style-type: decimal">
<li>The results are always a tibble.</li>
<li>The column names of the tibble are always predictable.</li>
<li>There are always as many rows in the tibble as there are in the input data set.</li>
</ol>
<p>For example, when numeric data are predicted:</p>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1042-1"><a href="model-choice.html#cb1042-1"></a>ames_test_small &lt;-<span class="st"> </span>ames_test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)</span>
<span id="cb1042-2"><a href="model-choice.html#cb1042-2"></a><span class="kw">predict</span>(lm_form_fit, <span class="dt">new_data =</span> ames_test_small)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 1
##   .pred
##   &lt;dbl&gt;
## 1  5.22
## 2  5.29
## 3  5.28
## 4  5.26
## 5  5.24</code></pre>
<p>The row order of the predictions are always the same as the original data. Why are there leading dot in some of the column names? Some tidyverse and tidymodels arguments and return values contain periods. This is to protect against merging data with duplicate names. There are some data sets that contain predictors names <code>pred</code>!</p>
<p>These three rules make it easier to merge predictions with the original data:</p>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="model-choice.html#cb1044-1"></a>ames_test_small <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1044-2"><a href="model-choice.html#cb1044-2"></a><span class="st">  </span><span class="kw">select</span>(Sale_Price) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1044-3"><a href="model-choice.html#cb1044-3"></a><span class="st">  </span><span class="kw">bind_cols</span>(<span class="kw">predict</span>(lm_form_fit, ames_test_small)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1044-4"><a href="model-choice.html#cb1044-4"></a><span class="st">  </span></span>
<span id="cb1044-5"><a href="model-choice.html#cb1044-5"></a><span class="st">  </span><span class="co"># Add 95% prediction intervals to the results:</span></span>
<span id="cb1044-6"><a href="model-choice.html#cb1044-6"></a><span class="st">  </span></span>
<span id="cb1044-7"><a href="model-choice.html#cb1044-7"></a><span class="st">  </span><span class="kw">bind_cols</span>(<span class="kw">predict</span>(lm_form_fit, ames_test_small, <span class="dt">type =</span> <span class="st">"pred_int"</span>)) </span></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   Sale_Price .pred .pred_lower .pred_upper
##        &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
## 1       5.39  5.22        4.90        5.53
## 2       5.28  5.29        4.97        5.60
## 3       5.27  5.28        4.96        5.59
## 4       5.60  5.26        4.95        5.58
## 5       5.02  5.24        4.93        5.55</code></pre>
<p>The motivation for the first rule comes from some R packages producing dissimilar data types from prediction functions. For example, the <strong>ranger</strong> package is an excellent tool for computing random forest models. However, instead of returning a data frame or vector as output, a specialized object is returned that has multiple values embedded within it (including the predicted values). This is just one more step for the data analyst to work around in their scripts. As another example, the <strong>glmnet</strong> package can return at least four different output types for predictions, depending on the model and characteristics of the data:</p>
<table>
<thead><tr class="header">
<th>Type of Prediction</th>
<th>Returns a:</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>numeric</td>
<td>numeric matrix</td>
</tr>
<tr class="even">
<td>class</td>
<td>
<em>character</em> matrix</td>
</tr>
<tr class="odd">
<td>probability (2 classes)</td>
<td>numeric matrix (2nd level only)</td>
</tr>
<tr class="even">
<td>probability (3+ classes)</td>
<td>3D numeric array (all levels)</td>
</tr>
</tbody>
</table>
<p>Additionally, the column names of the results contain coded values that map to a vector called <code>lambda</code> within the glmnet model object. This excellent statistical method can be discouraging to use in practice because of all of the special cases an analyst might encounter that require additional code to be useful.</p>
<p>For the second tidymodels prediction rule, the predictable column names for different types of predictions are:</p>
<pre><code>## # A tibble: 5 x 2
##   `type value` `column name(s)`            
##   &lt;chr&gt;        &lt;chr&gt;                       
## 1 `numeric`    `.pred`                     
## 2 `class`      `.pred_class`               
## 3 `prob`       `.pred_{class levels}`      
## 4 `conf_int`   `.pred_lower`, `.pred_upper`
## 5 `pred_int`   `.pred_lower`, `.pred_upper`</code></pre>
<p>The third rule regarding the number of rows in the output is critical. For example, if any rows of the new data contain missing values, the output will be padded with missing results for those rows.</p>
<p>A main advantage of standardizing the model interface and prediction types in <strong>parsnip</strong> is that, when different models are used, the syntax is identical. Suppose that we used a decision tree to model the Ames data. Outside of the model specification, there are no significant differences in the code pipeline:</p>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="model-choice.html#cb1047-1"></a>tree_model &lt;-<span class="st"> </span></span>
<span id="cb1047-2"><a href="model-choice.html#cb1047-2"></a><span class="st">  </span><span class="kw">decision_tree</span>(<span class="dt">min_n =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1047-3"><a href="model-choice.html#cb1047-3"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"rpart"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1047-4"><a href="model-choice.html#cb1047-4"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>)</span>
<span id="cb1047-5"><a href="model-choice.html#cb1047-5"></a></span>
<span id="cb1047-6"><a href="model-choice.html#cb1047-6"></a>tree_fit &lt;-<span class="st"> </span></span>
<span id="cb1047-7"><a href="model-choice.html#cb1047-7"></a><span class="st">  </span>tree_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1047-8"><a href="model-choice.html#cb1047-8"></a><span class="st">  </span><span class="kw">fit</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Longitude <span class="op">+</span><span class="st"> </span>Latitude, <span class="dt">data =</span> ames_train)</span>
<span id="cb1047-9"><a href="model-choice.html#cb1047-9"></a></span>
<span id="cb1047-10"><a href="model-choice.html#cb1047-10"></a>ames_test_small <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1047-11"><a href="model-choice.html#cb1047-11"></a><span class="st">  </span><span class="kw">select</span>(Sale_Price) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1047-12"><a href="model-choice.html#cb1047-12"></a><span class="st">  </span><span class="kw">bind_cols</span>(<span class="kw">predict</span>(tree_fit, ames_test_small))</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   Sale_Price .pred
##        &lt;dbl&gt; &lt;dbl&gt;
## 1       5.39  5.16
## 2       5.28  5.31
## 3       5.27  5.31
## 4       5.60  5.31
## 5       5.02  5.16</code></pre>
<p>This demonstrates the benefit of homogenizing the data analysis process and syntax across different models. It enables the user to spend their time on the results and interpretation rather than having to focus on the syntactical differences between R packages.</p>
<p>We have introduced the <strong>parsnip</strong> package, which provides a common interface for models across R packages using a standard syntax. The interface and resulting objects have a predictable structure.</p>
<p>The code for modeling the Ames data that we will use moving forward is:</p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1049-1"><a href="model-choice.html#cb1049-1"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb1049-2"><a href="model-choice.html#cb1049-2"></a><span class="kw">data</span>(ames)</span>
<span id="cb1049-3"><a href="model-choice.html#cb1049-3"></a>ames &lt;-<span class="st"> </span><span class="kw">mutate</span>(ames, <span class="dt">Sale_Price =</span> <span class="kw">log10</span>(Sale_Price))</span>
<span id="cb1049-4"><a href="model-choice.html#cb1049-4"></a></span>
<span id="cb1049-5"><a href="model-choice.html#cb1049-5"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1049-6"><a href="model-choice.html#cb1049-6"></a>ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ames, <span class="dt">prob =</span> <span class="fl">0.80</span>, <span class="dt">strata =</span> Sale_Price)</span>
<span id="cb1049-7"><a href="model-choice.html#cb1049-7"></a>ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)</span>
<span id="cb1049-8"><a href="model-choice.html#cb1049-8"></a>ames_test  &lt;-<span class="st">  </span><span class="kw">testing</span>(ames_split)</span>
<span id="cb1049-9"><a href="model-choice.html#cb1049-9"></a></span>
<span id="cb1049-10"><a href="model-choice.html#cb1049-10"></a>ames_rec &lt;-<span class="st"> </span></span>
<span id="cb1049-11"><a href="model-choice.html#cb1049-11"></a><span class="st">  </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>Year_Built <span class="op">+</span><span class="st"> </span>Bldg_Type <span class="op">+</span><span class="st"> </span></span>
<span id="cb1049-12"><a href="model-choice.html#cb1049-12"></a><span class="st">           </span>Latitude <span class="op">+</span><span class="st"> </span>Longitude, <span class="dt">data =</span> ames_train) <span class="op">%&gt;%</span></span>
<span id="cb1049-13"><a href="model-choice.html#cb1049-13"></a><span class="st">  </span><span class="kw">step_log</span>(Gr_Liv_Area, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1049-14"><a href="model-choice.html#cb1049-14"></a><span class="st">  </span><span class="kw">step_other</span>(Neighborhood, <span class="dt">threshold =</span> <span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1049-15"><a href="model-choice.html#cb1049-15"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1049-16"><a href="model-choice.html#cb1049-16"></a><span class="st">  </span><span class="kw">step_interact</span>( <span class="op">~</span><span class="st"> </span>Gr_Liv_Area<span class="op">:</span><span class="kw">starts_with</span>(<span class="st">"Bldg_Type_"</span>) ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1049-17"><a href="model-choice.html#cb1049-17"></a><span class="st">  </span><span class="kw">step_ns</span>(Latitude, Longitude, <span class="dt">deg_free =</span> <span class="dv">20</span>)</span>
<span id="cb1049-18"><a href="model-choice.html#cb1049-18"></a></span>
<span id="cb1049-19"><a href="model-choice.html#cb1049-19"></a>lm_model &lt;-<span class="st"> </span><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>)</span></code></pre></div>
</div>
</div>
<div id="performance" class="section level2">
<h2>
<span class="header-section-number">10.5</span> Judging model effectiveness</h2>
<p>Once we have a model, we need to know how well it works. A quantitative approach for estimating effectiveness allows us to understand the model, to compare different models, or to tweak the model to improve performance. Our focus in tidymodels is on <em>empirical validation</em>; this usually means using data that were not used to create the model as the substrate to measure effectiveness.</p>
<p>The choice of which metrics to examine can be critical. In later chapters, certain model parameters will be empirically optimized and a primary performance metric will be used to choose the best <em>sub-model</em>. Choosing the wrong method can easily result in unintended consequences. For example, two common metrics for regression models are the root mean squared error (RMSE) and the coefficient of determination (a.k.a. <span class="math inline">\(R^2\)</span>). The former measures <em>accuracy</em> while the latter measures <em>correlation</em>. These are not necessarily the same thing. This figure demonstrates the difference between the two:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-850-1.png" width="672"></p>
<p>A model optimized for RMSE has more variability but has relatively uniform accuracy across the range of the outcome. The right panel shows that there is a tighter correlation between the observed and predicted values but this model performs poorly in the tails.</p>
<p>This chapter will largely focus on the <strong>yardstick</strong> package. Before illustrating syntax, let’s explore whether empirical validation using performance metrics is worthwhile when a model is focused on inference rather than prediction.</p>
<div id="performance-metrics-and-inference" class="section level3">
<h3>
<span class="header-section-number">10.5.1</span> Performance metrics and inference</h3>
<p>The effectiveness of any given model depends on how the model will be used. An inferential model is used primarily to understand relationships, and typically is discussed with a strong focus on the choice (and validity) of probabilistic distributions and other generative qualities that define the model. For a model used primarily for prediction, by contrast, predictive strength is primary and concerns about underlying statistical qualities may be less important. Predictive strength is usually focused on how close our predictions come to the observed data, i.e., fidelity of the model predictions to the actual results. This chapter focuses on functions that can be used to measure predictive strength. However, our advice for those developing inferential models is to use these techniques <em>even when the model will not be used with the primary goal of prediction</em>.</p>
<p>A longstanding issue with the practice of inferential statistics is that, with a focus purely on inference, it is difficult to assess the credibility of a model. For example, consider the Alzheimer’s disease data when 333 patients were studied to determine the factors that influence cognitive impairment. An analysis might take the known risk factors and build a logistic regression model where the outcome is binary (impaired/non-impaired). Let’s consider predictors for age, sex, and the Apolipoprotein E genotype. The latter is a categorical variable with the six possible combinations of the three main variants of this gene. Apolipoprotein E is known to have an association with dementia.</p>
<p>A superficial, but not uncommon, approach to this analysis would be to fit a large model with main effects and interactions, then use statistical tests to find the minimal set of model terms that are statistically significant at some pre-defined level. If a full model with the three factors and their two- and three-way interactions were used, an initial phase would be to test the interactions using sequential likelihood ratio tests.</p>
<ul>
<li><p>When comparing the model with all two-way interactions to one with the additional three-way interaction, the likelihood ratio tests produces a p-value of 0.89. This implies that there is no evidence that the 4 additional model terms associated with the three-way interaction explain enough of the variation in the data to keep them in the model.</p></li>
<li><p>Next, the two-way interactions are similarly evaluated against the model with no interactions. The p-value here is 0.04. This is somewhat borderline, but, given the small sample size, it would be prudent to conclude that there is evidence that some of the 10 possible two-way interactions are important to the model.</p></li>
<li><p>From here, we would build some explanation of the results. The interactions would be particularly important to discuss since they may spark interesting physiological or neurological hypotheses to be explored further.</p></li>
</ul>
<p>While shallow, this analysis strategy is common in practice as well as in the literature. This is especially true if the practitioner has limited formal training in data analysis.</p>
<p>One missing piece of information in this approach is how closely this model fits the actual data. Using resampling methods, discussed in Chapter <a href="#resampling"><strong>??</strong></a>, we can estimate the accuracy of this model to be about 73.3%. Accuracy is often a poor measure of model performance; we use it here because it is commonly understood. If the model has 73.3% fidelity to the data, should we trust the conclusions produced by the model? We might think so until we realize that the baseline rate of non-impaired patients in the data is 72.7%. This means that, despite our statistical analysis, the two-factor model appears to be <em>only 0.6% better than a simple heuristic that always predicts patients to be unimpaired</em>, irregardless of the observed data.</p>
<!-- DK: Never seen this sort of object before. -->
<div class="rmdnote">
<p>
The point of this analysis is to demonstrate the idea that <strong>optimization of statistical characteristics of the model does not imply that the model fits the data well.</strong> Even for purely inferential models, some measure of fidelity to the data should accompany the inferential results. Using this, the consumers of the analyses can calibrate their expectations of the results of the statistical analysis.
</p>
</div>
<p>In the remainder of this chapter, general approaches for evaluating models via empirical validation are discussed. These approaches are grouped by the nature of the outcome data: purely numeric, binary classes, and three or more class levels.</p>
</div>
<div id="regression-metrics" class="section level3">
<h3>
<span class="header-section-number">10.5.2</span> Regression metrics</h3>
<p>Recall from Section <a href="model-choice.html#parsnip-predictions">10.4.3</a> that tidymodels prediction functions produce tibbles with columns for the predicted values. These columns have consistent names, and the functions in the <strong>yardstick</strong> package that produce performance metrics have consistent interfaces. The functions are data frame-based, as opposed to vector-based, with the general syntax of:</p>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1050-1"><a href="model-choice.html#cb1050-1"></a><span class="cf">function</span>(data, truth, ...)</span></code></pre></div>
<p>where <code>data</code> is a data frame or tibble and <code>truth</code> is the column with the observed outcome values. The ellipses or other arguments are used to specify the column(s) containing the predictions.</p>
<p>To illustrate, let’s take the model from Section <a href="#workflows-summary"><strong>??</strong></a>. The <code>lm_wflow_fit</code> object was a linear regression model whose predictor set was supplemented with an interaction and spline functions for longitude and latitude. It was created from a training set (named <code>ames_train</code>). Although we do not advise using the test set at this juncture of the modeling process, it will be used to illustrate functionality and syntax. The data frame <code>ames_test</code> consists of 731 properties. To start, let’s produce predictions:</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="model-choice.html#cb1051-1"></a>ames_test_res &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_fit, <span class="dt">new_data =</span> ames_test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Sale_Price))</span>
<span id="cb1051-2"><a href="model-choice.html#cb1051-2"></a>ames_test_res</span></code></pre></div>
<pre><code>## # A tibble: 731 x 1
##    .pred
##    &lt;dbl&gt;
##  1  5.31
##  2  5.30
##  3  5.17
##  4  5.52
##  5  5.09
##  6  5.49
##  7  5.51
##  8  5.43
##  9  5.55
## 10  5.24
## # … with 721 more rows</code></pre>
<p>The predicted numeric outcome from the regression model is named <code>.pred</code>. Let’s match the predicted values with their corresponding observed outcome values:</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="model-choice.html#cb1053-1"></a>ames_test_res &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(ames_test_res, ames_test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(Sale_Price))</span>
<span id="cb1053-2"><a href="model-choice.html#cb1053-2"></a>ames_test_res</span></code></pre></div>
<pre><code>## # A tibble: 731 x 2
##    .pred Sale_Price
##    &lt;dbl&gt;      &lt;dbl&gt;
##  1  5.31       5.39
##  2  5.30       5.28
##  3  5.17       5.27
##  4  5.52       5.60
##  5  5.09       5.02
##  6  5.49       5.49
##  7  5.51       5.60
##  8  5.43       5.34
##  9  5.55       5.51
## 10  5.24       5.30
## # … with 721 more rows</code></pre>
<p>Note that both the predicted and observed outcomes are in log10 units. It is best practice to analyze the predictions on the transformed scale (if one were used) even if the predictions are reported using the original units.</p>
<p>Let’s plot the data before computing metrics:</p>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1055-1"><a href="model-choice.html#cb1055-1"></a><span class="kw">ggplot</span>(ames_test_res, <span class="kw">aes</span>(<span class="dt">x =</span> Sale_Price, <span class="dt">y =</span> .pred)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1055-2"><a href="model-choice.html#cb1055-2"></a><span class="st">  </span><span class="co"># Create a diagonal line:</span></span>
<span id="cb1055-3"><a href="model-choice.html#cb1055-3"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">lty =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1055-4"><a href="model-choice.html#cb1055-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1055-5"><a href="model-choice.html#cb1055-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">"Predicted Sale Price (log10)"</span>, <span class="dt">x =</span> <span class="st">"Sale Price (log10)"</span>) <span class="op">+</span></span>
<span id="cb1055-6"><a href="model-choice.html#cb1055-6"></a><span class="st">  </span><span class="co"># Scale and size the x- and y-axis uniformly:</span></span>
<span id="cb1055-7"><a href="model-choice.html#cb1055-7"></a><span class="st">  </span><span class="kw">coord_obs_pred</span>()</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-855-1.png" width="672"></p>
<p>There is one property that is substantially over-predicted.</p>
<p>Let’s compute the root mean squared error for this model using the <code>rmse()</code> function:</p>
<div class="sourceCode" id="cb1056"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1056-1"><a href="model-choice.html#cb1056-1"></a><span class="kw">rmse</span>(ames_test_res, <span class="dt">truth =</span> Sale_Price, <span class="dt">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      0.0808</code></pre>
<p>The output above shows the standard format of the output of <strong>yardstick</strong> functions. Metrics for numeric outcomes usually have a value of “standard” for the <code>.estimator</code> column. Examples with different values for this column are shown below.</p>
<p>To compute multiple metrics at once, we can create a <em>metric set</em>. Let’s add <span class="math inline">\(R^2\)</span> and the mean absolute error:</p>
<div class="sourceCode" id="cb1058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1058-1"><a href="model-choice.html#cb1058-1"></a>ames_metrics &lt;-<span class="st"> </span><span class="kw">metric_set</span>(rmse, rsq, mae)</span>
<span id="cb1058-2"><a href="model-choice.html#cb1058-2"></a><span class="kw">ames_metrics</span>(ames_test_res, <span class="dt">truth =</span> Sale_Price, <span class="dt">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      0.0808
## 2 rsq     standard      0.795 
## 3 mae     standard      0.0558</code></pre>
<p>This tidy data format stacks the metrics vertically.</p>
<p>The <strong>yardstick</strong> package does <em>not</em> contain a function for adjusted <span class="math inline">\(R^2\)</span>. This commonly used modification of the coefficient of determination is needed when the same data used to fit the model are used to evaluate the model. This metric is not full supported in tidymodels because it is always a better approach to compute performance on a separate data set than the one used to fit the model.</p>
</div>
<div id="binary-classification-metrics" class="section level3">
<h3>
<span class="header-section-number">10.5.3</span> Binary classification metrics</h3>
<p>To illustrate other ways to measure model performance, we will switch to a different example. The <strong>modeldata</strong> package contains example predictions from a test data set with two classes (“Class1” and “Class2”):</p>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="model-choice.html#cb1060-1"></a><span class="kw">data</span>(two_class_example)</span>
<span id="cb1060-2"><a href="model-choice.html#cb1060-2"></a><span class="kw">str</span>(two_class_example)</span></code></pre></div>
<pre><code>## 'data.frame':	500 obs. of  4 variables:
##  $ truth    : Factor w/ 2 levels "Class1","Class2": 2 1 2 1 2 1 1 1 2 2 ...
##  $ Class1   : num  0.00359 0.67862 0.11089 0.73516 0.01624 ...
##  $ Class2   : num  0.996 0.321 0.889 0.265 0.984 ...
##  $ predicted: Factor w/ 2 levels "Class1","Class2": 2 1 2 1 2 1 1 1 2 2 ...</code></pre>
<p>The second and third columns are the predicted class probabilities for the test set while <code>predicted</code> are the discrete predictions.</p>
<p>For the hard class predictions, there are a variety of <strong>yardstick</strong> functions that are helpful:</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="model-choice.html#cb1062-1"></a><span class="co"># A confusion matrix: </span></span>
<span id="cb1062-2"><a href="model-choice.html#cb1062-2"></a><span class="kw">conf_mat</span>(two_class_example, <span class="dt">truth =</span> truth, <span class="dt">estimate =</span> predicted)</span></code></pre></div>
<pre><code>##           Truth
## Prediction Class1 Class2
##     Class1    227     50
##     Class2     31    192</code></pre>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="model-choice.html#cb1064-1"></a><span class="kw">accuracy</span>(two_class_example, <span class="dt">truth =</span> truth, <span class="dt">estimate =</span> predicted)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.838</code></pre>
<div class="sourceCode" id="cb1066"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1066-1"><a href="model-choice.html#cb1066-1"></a><span class="co"># Matthews correlation coefficient:</span></span>
<span id="cb1066-2"><a href="model-choice.html#cb1066-2"></a><span class="kw">mcc</span>(two_class_example, truth, predicted)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 mcc     binary         0.677</code></pre>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1068-1"><a href="model-choice.html#cb1068-1"></a><span class="co"># F1 metric:</span></span>
<span id="cb1068-2"><a href="model-choice.html#cb1068-2"></a><span class="kw">f_meas</span>(two_class_example, truth, predicted)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 f_meas  binary         0.849</code></pre>
<p>For binary classification data sets, these functions have a standard argument called <code>event_level</code>. The <em>default</em> is that the <strong>first</strong> level of the outcome factor is the event of interest.</p>
<div class="rmdnote">
<p>
There is some heterogeneity in R functions in this regard; some use the first level and others the second to denote the event of interest. We consider it more intuitive that the first level is the most important. The second level logic is borne of encoding the outcome as 0/1 (in which case the second value is the event) and unfortunately remains in some packages. However, tidymodels (along with many other R packages) <em>require</em> a categorical outcome to be encoded as a factor and, for this reason, the legacy justification for the second level as the event becomes irrelevant.
</p>
</div>
<p>As an example where the second class is the event:</p>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1070-1"><a href="model-choice.html#cb1070-1"></a><span class="kw">f_meas</span>(two_class_example, truth, predicted, <span class="dt">event_level =</span> <span class="st">"second"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 f_meas  binary         0.826</code></pre>
<p>In the output above, the <code>.estimator</code> value of “binary” indicates that the standard formula for binary classes will be used.</p>
<p>There are numerous classification metrics that use the predicted probabilities as inputs rather than the hard class predictions. For example, the receiver operating characteristic (ROC) curve computes the sensitivity and specificity over a continuum of different event thresholds. The predicted class column is not used. There are two <strong>yardstick</strong> functions for this method: <code>roc_curve()</code> computes the data points that make up the ROC curve and <code>roc_auc()</code> computes the area under the curve.</p>
<p>The interfaces to these types of metric functions use the <code>...</code> argument placeholder to pass in the appropriate class probability column. For two-class problems, the probability column for the event of interest is passed into the function:</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1072-1"><a href="model-choice.html#cb1072-1"></a>two_class_curve &lt;-<span class="st"> </span><span class="kw">roc_curve</span>(two_class_example, truth, Class1)</span>
<span id="cb1072-2"><a href="model-choice.html#cb1072-2"></a>two_class_curve</span></code></pre></div>
<pre><code>## # A tibble: 502 x 3
##    .threshold specificity sensitivity
##         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1 -Inf           0                 1
##  2    1.79e-7     0                 1
##  3    4.50e-6     0.00413           1
##  4    5.81e-6     0.00826           1
##  5    5.92e-6     0.0124            1
##  6    1.22e-5     0.0165            1
##  7    1.40e-5     0.0207            1
##  8    1.43e-5     0.0248            1
##  9    2.38e-5     0.0289            1
## 10    3.30e-5     0.0331            1
## # … with 492 more rows</code></pre>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1074-1"><a href="model-choice.html#cb1074-1"></a><span class="kw">roc_auc</span>(two_class_example, truth, Class1)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.939</code></pre>
<p>The <code>two_class_curve</code> object can be used in a <code>ggplot</code> call to visualize the curve. There is an <code>autoplot()</code> method that will take care of the details:</p>
<div class="sourceCode" id="cb1076"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1076-1"><a href="model-choice.html#cb1076-1"></a><span class="kw">autoplot</span>(two_class_curve)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/performance-2class-roc-curve-1.png" width="672"></p>
<p>There are a number of other functions that use probability estimates, including <code>gain_curve()</code>, <code>lift_curve()</code>, and <code>pr_curve()</code>.</p>
</div>
<div id="multi-class-classification-metrics" class="section level3">
<h3>
<span class="header-section-number">10.5.4</span> Multi-class classification metrics</h3>
<p>What about data with three or more classes? To demonstrate, let’s explore a different example data set that has four classes:</p>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="model-choice.html#cb1077-1"></a><span class="kw">data</span>(hpc_cv)</span>
<span id="cb1077-2"><a href="model-choice.html#cb1077-2"></a><span class="kw">str</span>(hpc_cv)</span></code></pre></div>
<pre><code>## 'data.frame':	3467 obs. of  7 variables:
##  $ obs     : Factor w/ 4 levels "VF","F","M","L": 1 1 1 1 1 1 1 1 1 1 ...
##  $ pred    : Factor w/ 4 levels "VF","F","M","L": 1 1 1 1 1 1 1 1 1 1 ...
##  $ VF      : num  0.914 0.938 0.947 0.929 0.942 ...
##  $ F       : num  0.0779 0.0571 0.0495 0.0653 0.0543 ...
##  $ M       : num  0.00848 0.00482 0.00316 0.00579 0.00381 ...
##  $ L       : num  1.99e-05 1.01e-05 5.00e-06 1.56e-05 7.29e-06 ...
##  $ Resample: chr  "Fold01" "Fold01" "Fold01" "Fold01" ...</code></pre>
<p>As before, there are factors for the observed and predicted outcomes along with four other columns of predicted probabilities for each class. These data also include a <code>Resample</code> column. These results are for out-of-sample predictions associated with 10-fold cross-validation (discussed in Chapter <a href="#resampling"><strong>??</strong></a>). For the time being, this column will be ignored.</p>
<p>The functions for metrics that use the discrete class probabilities are identical:</p>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="model-choice.html#cb1079-1"></a><span class="kw">accuracy</span>(hpc_cv, obs, pred)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy multiclass     0.709</code></pre>
<div class="sourceCode" id="cb1081"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1081-1"><a href="model-choice.html#cb1081-1"></a><span class="kw">mcc</span>(hpc_cv, obs, pred)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 mcc     multiclass     0.515</code></pre>
<p>Note that, in these results, a “multiclass” <code>.estimator</code> is listed. Like “binary”, this indicates that the formulas for outcomes with three or more class levels was used. The Matthews correlation coefficient was originally designed for two classes but has been extended to cases with more class levels.</p>
<p>There are methods for using metrics that are specific to outcomes with two classes for data sets with more than two classes. For example, a metric such as sensitivity measures the true positive rate which, by definition, is specific to two classes (i.e., “event” and “non-event”). How can this metric be used in our example data?</p>
<p>There are wrapper methods that can be used to apply sensitivity to our four-class outcome. These options are macro-, macro-weighted, and micro-averaging:</p>
<ul>
<li><p>Macro-averaging computes a set of one-versus-all metrics using the standard two-class statistics. These are averaged.</p></li>
<li><p>Macro-weighted averaging does the same but the average is weighted by the number of samples in each class.</p></li>
<li><p>Micro-averaging computes the contribution for each class, aggregates them, then computes a single metric from the aggregates.</p></li>
</ul>
<p>Using sensitivity as an example, the usual two-class calculation is the ratio of the number of correctly predicted events divided by the number of true events. The “manual” calculations for these averaging methods are:</p>
<div class="sourceCode" id="cb1083"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1083-1"><a href="model-choice.html#cb1083-1"></a>class_totals &lt;-<span class="st"> </span></span>
<span id="cb1083-2"><a href="model-choice.html#cb1083-2"></a><span class="st">  </span><span class="kw">count</span>(hpc_cv, obs, <span class="dt">name =</span> <span class="st">"totals"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1083-3"><a href="model-choice.html#cb1083-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">class_wts =</span> totals <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(totals))</span>
<span id="cb1083-4"><a href="model-choice.html#cb1083-4"></a>class_totals</span></code></pre></div>
<pre><code>##   obs totals class_wts
## 1  VF   1769      0.51
## 2   F   1078      0.31
## 3   M    412      0.12
## 4   L    208      0.06</code></pre>
<div class="sourceCode" id="cb1085"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1085-1"><a href="model-choice.html#cb1085-1"></a>cell_counts &lt;-<span class="st"> </span></span>
<span id="cb1085-2"><a href="model-choice.html#cb1085-2"></a><span class="st">  </span>hpc_cv <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1085-3"><a href="model-choice.html#cb1085-3"></a><span class="st">  </span><span class="kw">group_by</span>(obs, pred) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1085-4"><a href="model-choice.html#cb1085-4"></a><span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1085-5"><a href="model-choice.html#cb1085-5"></a><span class="st">  </span><span class="kw">ungroup</span>()</span>
<span id="cb1085-6"><a href="model-choice.html#cb1085-6"></a></span>
<span id="cb1085-7"><a href="model-choice.html#cb1085-7"></a><span class="co"># Compute the four sensitivities using 1-vs-all</span></span>
<span id="cb1085-8"><a href="model-choice.html#cb1085-8"></a>one_versus_all &lt;-<span class="st"> </span></span>
<span id="cb1085-9"><a href="model-choice.html#cb1085-9"></a><span class="st">  </span>cell_counts <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1085-10"><a href="model-choice.html#cb1085-10"></a><span class="st">  </span><span class="kw">filter</span>(obs <span class="op">==</span><span class="st"> </span>pred) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1085-11"><a href="model-choice.html#cb1085-11"></a><span class="st">  </span><span class="kw">full_join</span>(class_totals, <span class="dt">by =</span> <span class="st">"obs"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1085-12"><a href="model-choice.html#cb1085-12"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sens =</span> n <span class="op">/</span><span class="st"> </span>totals)</span>
<span id="cb1085-13"><a href="model-choice.html#cb1085-13"></a>one_versus_all</span></code></pre></div>
<pre><code>## # A tibble: 4 x 6
##   obs   pred      n totals class_wts  sens
##   &lt;fct&gt; &lt;fct&gt; &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1 VF    VF     1620   1769    0.510  0.916
## 2 F     F       647   1078    0.311  0.600
## 3 M     M        79    412    0.119  0.192
## 4 L     L       111    208    0.0600 0.534</code></pre>
<div class="sourceCode" id="cb1087"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1087-1"><a href="model-choice.html#cb1087-1"></a><span class="co"># Three different estimates:</span></span>
<span id="cb1087-2"><a href="model-choice.html#cb1087-2"></a>one_versus_all <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1087-3"><a href="model-choice.html#cb1087-3"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb1087-4"><a href="model-choice.html#cb1087-4"></a>    <span class="dt">macro =</span> <span class="kw">mean</span>(sens), </span>
<span id="cb1087-5"><a href="model-choice.html#cb1087-5"></a>    <span class="dt">macro_wts =</span> <span class="kw">weighted.mean</span>(sens, class_wts),</span>
<span id="cb1087-6"><a href="model-choice.html#cb1087-6"></a>    <span class="dt">micro =</span> <span class="kw">sum</span>(n) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(totals)</span>
<span id="cb1087-7"><a href="model-choice.html#cb1087-7"></a>  )</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   macro macro_wts micro
##   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1 0.560     0.709 0.709</code></pre>
<p>Thankfully, there are easier methods for obtaining these results:</p>
<div class="sourceCode" id="cb1089"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1089-1"><a href="model-choice.html#cb1089-1"></a><span class="kw">sensitivity</span>(hpc_cv, obs, pred, <span class="dt">estimator =</span> <span class="st">"macro"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 sens    macro          0.560</code></pre>
<div class="sourceCode" id="cb1091"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1091-1"><a href="model-choice.html#cb1091-1"></a><span class="kw">sensitivity</span>(hpc_cv, obs, pred, <span class="dt">estimator =</span> <span class="st">"macro_weighted"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator     .estimate
##   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;
## 1 sens    macro_weighted     0.709</code></pre>
<div class="sourceCode" id="cb1093"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1093-1"><a href="model-choice.html#cb1093-1"></a><span class="kw">sensitivity</span>(hpc_cv, obs, pred, <span class="dt">estimator =</span> <span class="st">"micro"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 sens    micro          0.709</code></pre>
<p>For metrics using probability estimates, there are some metrics with multi-class analogs. In this case, <em>all</em> of the class probability columns must be given to the function:</p>
<div class="sourceCode" id="cb1095"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1095-1"><a href="model-choice.html#cb1095-1"></a><span class="kw">roc_auc</span>(hpc_cv, obs, VF, F, M, L)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc hand_till      0.829</code></pre>
<p>Macro-averaging is also available:</p>
<div class="sourceCode" id="cb1097"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1097-1"><a href="model-choice.html#cb1097-1"></a><span class="kw">roc_auc</span>(hpc_cv, obs, VF, F, M, L, <span class="dt">estimator =</span> <span class="st">"macro_weighted"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator     .estimate
##   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;
## 1 roc_auc macro_weighted     0.868</code></pre>
<p>Finally, all of these performance metrics can be computed using <strong>dplyr</strong> groupings. Recall that these data have a column for the resampling groups. Passing a grouped data frame to the metric function will compute the metrics for each group:</p>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1099-1"><a href="model-choice.html#cb1099-1"></a>hpc_cv <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1099-2"><a href="model-choice.html#cb1099-2"></a><span class="st">  </span><span class="kw">group_by</span>(Resample) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1099-3"><a href="model-choice.html#cb1099-3"></a><span class="st">  </span><span class="kw">accuracy</span>(obs, pred)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 4
##    Resample .metric  .estimator .estimate
##    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
##  1 Fold01   accuracy multiclass     0.726
##  2 Fold02   accuracy multiclass     0.712
##  3 Fold03   accuracy multiclass     0.758
##  4 Fold04   accuracy multiclass     0.712
##  5 Fold05   accuracy multiclass     0.712
##  6 Fold06   accuracy multiclass     0.697
##  7 Fold07   accuracy multiclass     0.675
##  8 Fold08   accuracy multiclass     0.721
##  9 Fold09   accuracy multiclass     0.673
## 10 Fold10   accuracy multiclass     0.699</code></pre>
<p>The groupings also translate to the <code>autoplot()</code> methods:</p>
<div class="sourceCode" id="cb1101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1101-1"><a href="model-choice.html#cb1101-1"></a><span class="co"># Four 1-vs-all ROC curves for each fold</span></span>
<span id="cb1101-2"><a href="model-choice.html#cb1101-2"></a></span>
<span id="cb1101-3"><a href="model-choice.html#cb1101-3"></a>hpc_cv <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1101-4"><a href="model-choice.html#cb1101-4"></a><span class="st">  </span><span class="kw">group_by</span>(Resample) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1101-5"><a href="model-choice.html#cb1101-5"></a><span class="st">  </span><span class="kw">roc_curve</span>(obs, VF, F, M, L) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1101-6"><a href="model-choice.html#cb1101-6"></a><span class="st">  </span><span class="kw">autoplot</span>()</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-868-1.png" width="672"></p>
<p>This can be a quick visualization method for model effectiveness.</p>
<p>Functions from the <strong>yardstick</strong> package measure the effectiveness of a model using data. The primary interface is based on data frames (as opposed to having vector arguments). There are a variety of regression and classification metrics and, within these, there are sometimes different estimators for the statistics.</p>

</div>
</div>
</div></body></html>

<p style="text-align: center;">
<a href="n-parameters.html"><button class="btn btn-default">Previous</button></a>
<a href="continuous-response.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-10-08
</p>
</div>
</div>



</body>
</html>
