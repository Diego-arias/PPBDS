<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.2 Measuring uncertainty with confidence intervals | Preceptor’s Primer for Bayesian Data Science" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />

<meta name="author" content="David Kane" />

<meta name="date" content="2020-06-25" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="7.2 Measuring uncertainty with confidence intervals | Preceptor’s Primer for Bayesian Data Science">

<title>7.2 Measuring uncertainty with confidence intervals | Preceptor’s Primer for Bayesian Data Science</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Preceptor's Primer for Bayesian Data Science<p><p class="author">David Kane</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Cover</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Tidyverse</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a href="sampling.html"><span class="toc-section-number">6</span> Sampling</a>
<a href="confidence-intervals.html"><span class="toc-section-number">7</span> One Parameter</a>
<a href="two-parameters.html"><span class="toc-section-number">8</span> Two Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="regression.html"><span class="toc-section-number">10</span> Continuous Response I</a>
<a href="multiple-regression.html"><span class="toc-section-number">11</span> Continuous Response II</a>
<a href="classification.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="machine-learning.html"><span class="toc-section-number">13</span> Machine Learning</a>
<a href="animation.html"><span class="toc-section-number">14</span> Animation</a>
<a href="getting-help.html"><span class="toc-section-number">15</span> Getting Help</a>
<a href="maps.html"><span class="toc-section-number">16</span> Maps</a>
<a href="">(APPENDIX) Appendix</a>
<a href="productivity.html"><span class="toc-section-number">17</span> Productivity</a>
<a href="references.html">References</a>
<a href="shiny.html"><span class="toc-section-number">18</span> Shiny</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="ci-build-up" class="section level2">
<h2>
<span class="header-section-number">7.2</span> Measuring uncertainty with confidence intervals</h2>
<p>Let’s start this section with an analogy involving fishing. Say you are trying to catch a fish. On the one hand, you could use a spear, while on the other you could use a net. Using the net will probably allow you to catch more fish!</p>
<p>Now think back to our pennies exercise where you are trying to estimate the true population mean year <span class="math inline">\(\mu\)</span> of <em>all</em> US pennies.  Think of the value of <span class="math inline">\(\mu\)</span> as a fish.</p>
<p>On the one hand, we could use the appropriate <em>point estimate/sample statistic</em> to estimate <span class="math inline">\(\mu\)</span>, which we saw in Table <a href="#tab:table-ch8-b"><strong>??</strong></a> is the sample mean <span class="math inline">\(\overline{x}\)</span>. Based on our sample of 50 pennies from the bank, the sample mean was 1995.44. Think of using this value as “fishing with a spear.”</p>
<p>What would “fishing with a net” correspond to? Look at the bootstrap distribution in Figure <a href="#fig:one-thousand-sample-means"><strong>??</strong></a> once more. Between which two years would you say that “most” sample means lie? While this question is somewhat subjective, saying that most sample means lie between 1992 and 2000 would not be unreasonable. Think of this interval as the “net.”</p>
<p>What we’ve just illustrated is the concept of a <em>confidence interval</em>, which we’ll abbreviate with “CI” throughout this book. As opposed to a point estimate/sample statistic that estimates the value of an unknown population parameter with a single value, a <em>confidence interval</em>  gives what can be interpreted as a range of plausible values. Going back to our analogy, point estimates/sample statistics can be thought of as spears, whereas confidence intervals can be thought of as nets.</p>
<!--
Point estimate           |  Confidence interval
:-------------------------:|:-------------------------:
![](images/shutterstock/shutterstock_149730074_cropped.jpg){ height=2.5in } |  ![](images/shutterstock/shutterstock_176684936.jpg){ height=2.5in }
-->
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-39"></span>
<p class="caption marginnote shownote">
FIGURE 7.16: Analogy of difference between point estimates and confidence intervals.
</p>
<img src="07-one-parameter/images/point_estimate_vs_conf_int.png" alt="Analogy of difference between point estimates and confidence intervals.">
</div>
<p>Our proposed interval of 1992 to 2000 was constructed by eye and was thus somewhat subjective. We now introduce two methods for constructing such intervals in a more exact fashion: the <em>percentile method</em> and the <em>standard error method</em>.</p>
<p>Both methods for confidence interval construction share some commonalities. First, they are both constructed from a bootstrap distribution, as you constructed in Subsection <a href="resampling-tactile.html#bootstrap-1000-replicates">7.1.7</a> and visualized in Figure <a href="#fig:one-thousand-sample-means"><strong>??</strong></a>.</p>
<p>Second, they both require you to specify the  <em>confidence level</em>. Commonly used confidence levels include 90%, 95%, and 99%. All other things being equal, higher confidence levels correspond to wider confidence intervals, and lower confidence levels correspond to narrower confidence intervals. In this book, we’ll be mostly using 95% and hence constructing “95% confidence intervals for <span class="math inline">\(\mu\)</span>” for our pennies activity.</p>
<div id="percentile-method" class="section level3">
<h3>
<span class="header-section-number">7.2.1</span> Percentile method</h3>
<p>One method to construct a confidence interval is to use the middle 95% of values of the bootstrap distribution. We can do this by computing the 2.5th and 97.5th percentiles, which are 1991.2 and 1999.741, respectively. This is known as the <em>percentile method</em> for constructing confidence intervals. You can get these values using the <code>quantile()</code> function on the <code>mean_year</code> column of <code>virtual_resampled_means</code>:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="ci-build-up.html#cb42-1"></a>virtual_resampled_means <span class="op">%&gt;%</span></span>
<span id="cb42-2"><a href="ci-build-up.html#cb42-2"></a><span class="st">  </span><span class="kw">pull</span>(mean_year) <span class="op">%&gt;%</span></span>
<span id="cb42-3"><a href="ci-build-up.html#cb42-3"></a><span class="st">  </span><span class="kw">quantile</span>(<span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 1991.200 1999.741</code></pre>
<p>Let’s mark these percentiles on the bootstrap distribution with vertical lines in Figure <a href="#fig:percentile-method"><strong>??</strong></a>. About 95% of the <code>mean_year</code> variable values in <code>virtual_resampled_means</code> fall between 1991.2 and 1999.741, with 2.5% to the left of the leftmost line and 2.5% to the right of the rightmost line.</p>

<div class="figure">
<span id="fig:unnamed-chunk-42"></span>
<p class="caption marginnote shownote">
FIGURE 7.17: Percentile method 95% confidence interval. Interval endpoints marked by vertical lines.
</p>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-42-1.png" alt="Percentile method 95% confidence interval. Interval endpoints marked by vertical lines." width="672">
</div>
</div>
<div id="se-method" class="section level3">
<h3>
<span class="header-section-number">7.2.2</span> Standard error method</h3>
<p>If a numerical variable follows a normal distribution, or, in other words, the histogram of this variable is bell-shaped, then roughly 95% of values fall between <span class="math inline">\(\pm\)</span> 1.96 standard deviations of the mean. Given that our bootstrap distribution based on 1,000 resamples with replacement in Figure <a href="#fig:one-thousand-sample-means"><strong>??</strong></a> is normally shaped, let’s use this fact about normal distributions to construct a confidence interval in a different way.</p>
<p>First, recall the bootstrap distribution has a mean equal to 1995.51. This value almost coincides exactly with the value of the sample mean <span class="math inline">\(\overline{x}\)</span> of our original 50 pennies of 1995.44. Second, let’s compute the standard deviation of the bootstrap distribution using the values of <code>mean_year</code> in the <code>virtual_resampled_means</code> data frame:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="ci-build-up.html#cb44-1"></a>virtual_resampled_means <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb44-2"><a href="ci-build-up.html#cb44-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">SE =</span> <span class="kw">sd</span>(mean_year))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##      SE
##   &lt;dbl&gt;
## 1  2.18</code></pre>
<p>What is this value? Recall that the bootstrap distribution is an approximation to the sampling distribution. Recall also that the standard deviation of a sampling distribution has a special name: the <em>standard error</em>. Putting these two facts together, we can say that 2.17868 is an approximation of the standard error of <span class="math inline">\(\overline{x}\)</span>.</p>
<p>Thus, using our 95% rule of thumb about normal distributions, we can use the following formula to determine the lower and upper endpoints of a 95% confidence interval for <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\overline{x} \pm 1.96 \cdot SE &amp;= (\overline{x} - 1.96 \cdot SE, \overline{x} + 1.96 \cdot SE)\\
&amp;= (1995.44 - 1.96 \cdot 2.18, 1995.44 + 1.96 \cdot 2.18)\\
&amp;= (1991.15, 1999.73)
\end{aligned}
\]</span></p>
<p>Let’s now add the SE method confidence interval with dashed lines in Figure <a href="#fig:percentile-and-se-method"><strong>??</strong></a>.</p>

<pre><code>## Warning: attributes are not identical across measure variables;
## they will be dropped</code></pre>
<div class="figure">
<span id="fig:unnamed-chunk-45"></span>
<p class="caption marginnote shownote">
FIGURE 7.18: Comparing two 95% confidence interval methods.
</p>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-45-1.png" alt="Comparing two 95% confidence interval methods." width="672">
</div>
<p>We see that both methods produce nearly identical 95% confidence intervals for <span class="math inline">\(\mu\)</span> with the percentile method yielding <span class="math inline">\((1991.2, 1999.74)\)</span> while the standard error method produces <span class="math inline">\((1991.17, 1999.71)\)</span>. Thus, the standard error method can be a good quick way to construct confidence intervals when you already have an estimate of the standard error and don’t want to go through the steps to obtain a confidence interval by the percentile method. It is particularly handy since <span class="math inline">\(1.96 \approx 2\)</span>, and thus it is easy to calculate in one’s head. However, recall that we can only use the standard error rule when the bootstrap distribution is roughly normally shaped. If you have an unusually shaped distribution, it is better to use the percentile method.</p>
</div>
<div id="one-prop-ci" class="section level3">
<h3>
<span class="header-section-number">7.2.3</span> Interpreting confidence intervals</h3>
<p>Now that we’ve shown you how to construct confidence intervals using a sample drawn from a population, let’s now focus on how to interpret them.</p>
<p>The traditional approach is referred to as either “Frequentist” or “Classical.” In this interpretation, 95% of the time that you perform this exercise, the <em>intervals</em> constructed will contain the true but unknown population parameter. You are making a claim about how well this approach — bootstrap resampling — works if you do it many, many times. You do not know anything about how well it worked this time.</p>
<p>In this book, we use a “Bayesian” interpretation. There is a true, but unknown, average year of minting for all the pennies in the world. In theory, we could find all those pennies and then calculate this number. The Bayesian interpretation of a 95% confidence interval is that we are 95% certain that the true value is within the CI limits. It would be a fair wager to bet, at 19:1 odds, that the true value is outside those limits because there is a 5% chance that it is.</p>
<p>Note that these are just <em>interpretations</em>. The reality of what we did is the same in both cases. The computer code is the same. This Bayesian interpretation of the bootstrap confidence interval is often called a <a href="https://en.wikipedia.org/wiki/Credible_interval">credible interval</a> in the academic literature. You may find yourself in a statistics class that uses the phrase “confidence interval” to refer only to the <a href="https://en.wikipedia.org/wiki/Frequentist_inference">frequentist</a> concept.</p>
<p>Does our percentile-based confidence interval of (1991.2, 1999.74) “capture” the true mean year <span class="math inline">\(\mu\)</span> of <em>all</em> US pennies? Alas, we’ll never know, because we don’t know what the true value of <span class="math inline">\(\mu\)</span> is. After all, we’re sampling to estimate it!</p>
<p>However, we can answer a different question. Given that we’ve observed the 50 pennies that we did, what’s the <em>chance</em> that the true value falls within (1991.2, 1999.74)? If the answer is 95%, then we can call this a 95% interval.</p>
<p>This is a statement about <em>probability</em>. We thus can think of the mean year of the pennies as a random variable that has its own <em>probability distribution</em>. Of course, we don’t know exactly what that distribution is. The bootstrap resampling procedure, however, generates a distribution of values for the mean. Since the bootstrap distribution is a good approximation of the <em>sampling</em> distribution we learned about in the last chapter (see Subsection <a href="ci-conclusion.html#bootstrap-vs-sampling">7.8.1</a>), this is a reasonable thing to do. Then, if we take the bootstrap distribution as our “best guess” of the probability distribution of the variable we are interested in, we can guess that the variable has a 95% chance of lying between the 2.5th and 97.5th percentiles of the bootstrap distribution.</p>
<!-- AR: took this language from the regression chapter.  Maybe OK to repeat it
-->
<p>Instead of looking at confidence intervals, a common alternative approach is to conduct <em>hypothesis tests</em>, where one hypothesis is called the “null hypothesis” (often that a value, such as a mean, is equal to zero) and the result of the test is either <em>rejecting</em> the null hypothesis (so you’d conclude that the mean is not zero) or <em>failing to reject</em> the null hypothesis. The decision whether to reject the null hypothesis is generally made with reference to a <em>p-value</em>, a measure of how likely one would be, if the null hypothesis were true, to observe results at least as extreme as the results actually observed. A <em>p</em>-value cutoff, often 0.05, is employed: if the <em>p</em>-value is lower, the null hypothesis is rejected, otherwise the hypothesis is not rejected.</p>
<p>We think this is a bad way to make decisions. Two very similar datasets could produce <em>p</em>-values of <span class="math inline">\(p = 0.04\)</span> and <span class="math inline">\(p = 0.06\)</span> for a quantity of interest. If you would make one decision in the former case and a totally different decision in the latter case, then there’s something wrong with your decision-making process! Rather, we think it is more sensible to look at the data, construct models to summarize important features of the data, and make decisions based on those models that take into account the uncertainty in the models’ estimates.</p>
<!-- The above is not bad, but we need more, more, more. Every chapter should repeat this and provide examples. Maybe, each chapter, we need a specific example of the stupidity of NHST. (And maybe an actual decision problem.) And then show how a model summary helps us. -->
</div>
</div></body></html>

<p style="text-align: center;">
<a href="resampling-tactile.html"><button class="btn btn-default">Previous</button></a>
<a href="ci-width.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-06-25
</p>
</div>
</div>



</body>
</html>
